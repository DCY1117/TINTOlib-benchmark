{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "#import openslide\n",
    "#from openslide.deepzoom import DeepZoomGenerator\n",
    "import tifffile as tifi\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,mean_absolute_percentage_error\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import vgg16, vgg19, resnet50, mobilenet, inception_resnet_v2, densenet, inception_v3, xception, nasnet, ResNet152V2\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, InputLayer, LayerNormalization\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.optimizers import SGD, Adam, Adadelta, Adamax\n",
    "from keras import layers, models, Model\n",
    "from keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from keras.layers import Input, Activation, MaxPooling2D, Concatenate, AveragePooling2D\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Models of TINTOlib\n",
    "from TINTOlib.tinto import TINTO\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.combination import Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary CNN+MLP\n",
    "\n",
    "## Table of Contents\n",
    "1. [Dataset](#dataset)\n",
    "2. [Load and Preprocess](#load-and-preprocess)\n",
    "3. [Model Architectures](#model-architectures)\n",
    "4. [Metrics](#metrics)\n",
    "5. [Compile and Fit](#compile-and-fit)\n",
    "6. [Experiments](#experiments)\n",
    "    - [Experiment 1: TINTO](#experiment-1-tinto)\n",
    "    - [Experiment 2: IGTD](#experiment-2-igtd)\n",
    "    - [Experiment 3: REFINED](#experiment-3-refined)\n",
    "    - [Experiment 4: Bar Graph](#experiment-4-bar-graph)\n",
    "    - [Experiment 5: Distance Matrix](#experiment-5-distance-matrix)\n",
    "    - [Experiment 6: Combination](#experiment-6-combination)\n",
    "    - [Experiment 7: SuperTML](#experiment-7-supertml)\n",
    "7. [Final Metrics and Best Model](#final-metrics-and-best-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 64\n",
    "\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable to store dataset name\n",
    "dataset_name = 'preprocessed_heloc'\n",
    "results_path = f'logs/{dataset_name}/CNN+MLP_Binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../Datasets_benchmark/Binary/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD AND PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ExternalRiskEstimate', 'MSinceOldestTradeOpen',\n",
       "       'MSinceMostRecentTradeOpen', 'AverageMInFile', 'NumSatisfactoryTrades',\n",
       "       'NumTrades60Ever2DerogPubRec', 'NumTrades90Ever2DerogPubRec',\n",
       "       'PercentTradesNeverDelq', 'MSinceMostRecentDelq',\n",
       "       'MaxDelq2PublicRecLast12M', 'MaxDelqEver', 'NumTotalTrades',\n",
       "       'NumTradesOpeninLast12M', 'PercentInstallTrades',\n",
       "       'MSinceMostRecentInqexcl7days', 'NumInqLast6M', 'NumInqLast6Mexcl7days',\n",
       "       'NetFractionRevolvingBurden', 'NetFractionInstallBurden',\n",
       "       'NumRevolvingTradesWBalance', 'NumInstallTradesWBalance',\n",
       "       'NumBank2NatlTradesWHighUtilization', 'PercentTradesWBalance',\n",
       "       'RiskPerformance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9866    1\n",
      "9867    0\n",
      "9868    0\n",
      "9869    0\n",
      "9870    0\n",
      "Name: RiskPerformance, Length: 9871, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the last column with LabelEncoder\n",
    "df.iloc[:, -1] = label_encoder.fit_transform(df.iloc[:, -1])\n",
    "\n",
    "# Display the updated last column\n",
    "print(df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_and_preprocess_data(images_folder, image_model, problem_type):\n",
    "\n",
    "    # Generate the images if the folder does not exist\n",
    "    if not os.path.exists(images_folder):\n",
    "        #Generate thet images\n",
    "        image_model.generateImages(df, images_folder)\n",
    "    else:\n",
    "        print(\"The images are already generated\")\n",
    "\n",
    "    img_paths = os.path.join(images_folder,problem_type+\".csv\")\n",
    "\n",
    "    print(img_paths)\n",
    "    \n",
    "    imgs = pd.read_csv(img_paths)\n",
    "\n",
    "    # Update image paths\n",
    "    imgs[\"images\"] = images_folder + \"/\" + imgs[\"images\"]\n",
    "\n",
    "    # Combine datasets\n",
    "    combined_dataset = pd.concat([imgs, df], axis=1)\n",
    "\n",
    "    # Split data\n",
    "    df_x = combined_dataset.drop(df.columns[-1], axis=1).drop(\"class\", axis=1)\n",
    "    df_y = combined_dataset[\"class\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size=0.20, random_state=SEED, stratify=df_y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.50, random_state=SEED, stratify=y_val)\n",
    "    # Numerical data\n",
    "    X_train_num = X_train.drop(\"images\", axis=1)\n",
    "    X_val_num = X_val.drop(\"images\", axis=1)\n",
    "    X_test_num = X_test.drop(\"images\", axis=1)\n",
    "\n",
    "    # Image data\n",
    "    X_train_img = np.array([cv2.imread(img) for img in X_train[\"images\"]])\n",
    "    X_val_img = np.array([cv2.imread(img) for img in X_val[\"images\"]])\n",
    "    X_test_img = np.array([cv2.imread(img) for img in X_test[\"images\"]])\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Scale numerical data\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "    X_val_num = pd.DataFrame(scaler.transform(X_val_num), columns=X_val_num.columns)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(X_test_num), columns=X_test_num.columns)\n",
    "\n",
    "    attributes = len(X_train_num.columns)\n",
    "    imgs_shape = X_train_img[0].shape\n",
    "\n",
    "    print(\"Images shape: \",imgs_shape)\n",
    "    print(\"Attributres: \",attributes)\n",
    "    pixels=X_train_img[0].shape[0]\n",
    "    print(\"Image size (pixels):\", pixels)\n",
    "\n",
    "    return X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL ARCHITECTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small CNN + MLP\n",
    "\n",
    "def create_model1(attributes, imgs_shape):\n",
    "\n",
    "    # MLP branch\n",
    "    mlp_input = Input(shape=(attributes,))\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_input)\n",
    "    mlp_output = Dense(32, activation='relu')(mlp_output)\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_output)\n",
    "\n",
    "    # CNN branch\n",
    "    cnn_input = Input(shape=imgs_shape)\n",
    "    cnn_output = Conv2D(4, (2, 2), activation='relu')(cnn_input)\n",
    "    cnn_output = Flatten()(cnn_output)\n",
    "\n",
    "    # Concatenate the outputs of CNN and MLP branches\n",
    "    concat_output = Concatenate()([cnn_output, mlp_output])\n",
    "\n",
    "    # Final MLP layers\n",
    "    final_output = Dense(32, activation='relu')(concat_output)\n",
    "    final_output = Dense(16, activation='relu')(final_output)\n",
    "    final_output = Dense(8, activation='relu')(final_output)\n",
    "    final_output = Dense(1, activation='sigmoid')(final_output)  # Output layer for regression\n",
    "\n",
    "    # Create and return the model\n",
    "    model1 = Model(inputs=[mlp_input, cnn_input], outputs=final_output)\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medium CNN + MLP\n",
    "\n",
    "def create_model2(attributes, imgs_shape):\n",
    "\n",
    "    # MLP branch\n",
    "    mlp_dropout = 0.1\n",
    "    mlp_input = Input(shape=(attributes,))\n",
    "    # MLP brach 1\n",
    "    mlp_1 = Dense(1024, activation='relu')(mlp_input)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    mlp_1 = Dense(512, activation='relu')(mlp_1)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    mlp_1 = Dense(256, activation='relu')(mlp_1)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    mlp_1 = Dense(128, activation='relu')(mlp_1)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    mlp_1 = Dense(64, activation='relu')(mlp_1)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    mlp_1 = Dense(32, activation='relu')(mlp_1)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    mlp_1 = Dense(16, activation='relu')(mlp_1)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    # MLP brach 2\n",
    "    mlp_2 = Dense(1024, activation='relu')(mlp_input)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_2 = Dense(512, activation='relu')(mlp_2)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_2 = Dense(256, activation='relu')(mlp_2)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_2 = Dense(128, activation='relu')(mlp_2)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_2 = Dense(64, activation='relu')(mlp_2)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_2 = Dense(32, activation='relu')(mlp_2)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_2 = Dense(16, activation='relu')(mlp_2)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_output = Concatenate(axis=1)([mlp_1, mlp_2])\n",
    "\n",
    "    # CNN branch\n",
    "    cnn_dropout = 0.1\n",
    "    cnn_input = Input(shape=imgs_shape)\n",
    "    # CNN branch 1\n",
    "    tower_1 = Conv2D(16, (3,3), activation='relu',padding=\"same\")(cnn_input)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(cnn_dropout)(tower_1)\n",
    "\n",
    "    tower_1 = Conv2D(32, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(cnn_dropout)(tower_1)\n",
    "\n",
    "    tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(cnn_dropout)(tower_1)\n",
    "\n",
    "    tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(cnn_dropout)(tower_1)\n",
    "\n",
    "    # CNN branch 2\n",
    "    tower_2 = Conv2D(16, (5,5), activation='relu',padding=\"same\")(cnn_input)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(cnn_dropout)(tower_2)\n",
    "\n",
    "    tower_2 = Conv2D(32, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(cnn_dropout)(tower_2)\n",
    "\n",
    "    tower_2 = Conv2D(64, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(cnn_dropout)(tower_2)\n",
    "\n",
    "    tower_2 = Conv2D(64, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(cnn_dropout)(tower_2)\n",
    "\n",
    "    #Concatenate CNN branches\n",
    "    merged_cnn = Concatenate(axis=1)([tower_1, tower_2])\n",
    "\n",
    "    #Flatten\n",
    "    merged = Flatten()(merged_cnn)\n",
    "\n",
    "    #Dense layers\n",
    "    out = Dense(256, activation='relu')(merged)\n",
    "    out = Dropout(cnn_dropout)(merged)\n",
    "    out = Dense(128, activation='sigmoid')(out)\n",
    "    out = Dropout(cnn_dropout)(out)\n",
    "    out = Dense(64, activation='sigmoid')(out)\n",
    "    out = Dropout(cnn_dropout)(out)\n",
    "    out = Dense(32, activation='sigmoid')(out)\n",
    "    cnn_output = Dropout(cnn_dropout)(out)\n",
    "\n",
    "    # Concatenate the outputs of CNN and MLP branches\n",
    "    concat_output = Concatenate()([mlp_output, cnn_output])\n",
    "\n",
    "    # Final MLP layers\n",
    "    final_output = Dense(48, activation='relu')(concat_output)\n",
    "    final_output = Dense(1, activation='sigmoid')(final_output)  # Output layer for regression\n",
    "\n",
    "    # Create and return the model\n",
    "    model2 = Model(inputs=[mlp_input, cnn_input], outputs=final_output)\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    #tf.keras.metrics.TruePositives(name = 'tp'),\n",
    "    #tf.keras.metrics.FalsePositives(name = 'fp'),\n",
    "    #tf.keras.metrics.TrueNegatives(name = 'tn'),\n",
    "    #tf.keras.metrics.FalseNegatives(name = 'fn'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name ='accuracy'),\n",
    "    tf.keras.metrics.Precision(name = 'precision'),\n",
    "    tf.keras.metrics.Recall(name = 'recall'),\n",
    "    tf.keras.metrics.AUC(name = 'auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPILE AND FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, model_name, batch_size=32, epochs=200, lr=1e-3):\n",
    "\n",
    "    opt = Adam(learning_rate=lr)\n",
    "\n",
    "    # Define the early stopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',  # Monitor the validation loss\n",
    "        min_delta=0.001,     # Minimum change in the monitored quantity to qualify as an improvement\n",
    "        patience=20,          # Number of epochs with no improvement after which training will be stopped\n",
    "        verbose=1,           # Print messages when the callback takes an action\n",
    "        mode='min',           # Training will stop when the quantity monitored has stopped decreasing\n",
    "        restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=opt,\n",
    "        metrics=METRICS\n",
    "    )\n",
    "\n",
    "    model_history = model.fit(\n",
    "        x=[X_train_num,X_train_img], y=y_train,\n",
    "        validation_data=([X_val_num,X_val_img], y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    os.makedirs(f\"models/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['loss'], color = 'red', label = 'loss')\n",
    "    plt.plot(model_history.history['val_loss'], color = 'green', label = 'val loss')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/loss_plot.png\")\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['accuracy'], color = 'red', label = 'accuracy')\n",
    "    plt.plot(model_history.history['val_accuracy'], color = 'green', label = 'val accuracy')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/accuracy_plot.png\")\n",
    "\n",
    "    # Save the model\n",
    "    os.makedirs(f\"models/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "    model.save(f\"models/{dataset_name}/{model_name}/model_{dataset_name}.keras\")\n",
    "\n",
    "    # Evaluate the model on the training set\n",
    "    train_scores = model.evaluate([X_train_num,X_train_img], y_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_scores = model.evaluate([X_val_num,X_val_img], y_val)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    score_test = model.evaluate([X_test_num,X_test_img], y_test)\n",
    "\n",
    "    # Save training, validation, and test scores\n",
    "    metrics = {\n",
    "        'train_loss': train_scores[0],\n",
    "        'train_accuracy': train_scores[1],\n",
    "        'train_precision': train_scores[2],\n",
    "        'train_recall': train_scores[3],\n",
    "        'train_auc': train_scores[4],\n",
    "        'val_loss': val_scores[0],\n",
    "        'val_accuracy': val_scores[1],\n",
    "        'val_precision': val_scores[2],\n",
    "        'val_recall': val_scores[3],\n",
    "        'val_auc': val_scores[4],\n",
    "        'test_loss': score_test[0],\n",
    "        'test_accuracy': score_test[1],\n",
    "        'test_precision': score_test[2],\n",
    "        'test_recall': score_test[3],\n",
    "        'test_auc': score_test[4]\n",
    "    }\n",
    "\n",
    "    # Save metrics to a file\n",
    "    os.makedirs(f'{results_path}/{model_name}', exist_ok=True)\n",
    "    with open(f'{results_path}/{model_name}/{dataset_name}_metrics.txt', 'w') as f:\n",
    "        for key, value in metrics.items():\n",
    "            f.write(f'{key}: {value}\\n')\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test,dataset_name, model_name, batch_size=32, epochs=200, lr=1e-3):\n",
    "    try:\n",
    "        if model is None:\n",
    "            print(f\"Model {model_name} is None\")\n",
    "            return None\n",
    "        else:\n",
    "            metrics = compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test,dataset_name, model_name, batch_size, epochs, lr)\n",
    "            return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to compile and fit {model_name}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_create_model(create_model_func, attributes, imgs_shape):\n",
    "    try:\n",
    "        model = create_model_func(attributes, imgs_shape)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, blur=True, random_seed=SEED)\n",
    "#image_model = REFINED(problem= problem_type,hcIterations=5)\n",
    "#image_model = IGTD(problem= problem_type)\n",
    "#image_model = BarGraph(problem= problem_type)\n",
    "#image_model = DistanceMatrix(problem= problem_type)\n",
    "#image_model = Combination(problem= problem_type)\n",
    "#image_model = SuperTML(problem= problem_type)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_IGTD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default the seed is 1 for all experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 1: TINTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, blur=True, random_seed=SEED)\n",
    "name = f\"TINTO_blur\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, blur=True, option=\"maximum\", random_seed=SEED)\n",
    "name = f\"TINTO_blur_maximum\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, random_seed=SEED)\n",
    "name = f\"TINTO\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 2: IGTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the dataframe\n",
    "num_columns = df.shape[1]\n",
    "\n",
    "# Calculate number of columns - 1\n",
    "columns_minus_one = num_columns - 1\n",
    "\n",
    "# Calculate the square root for image size\n",
    "import math\n",
    "image_size = math.ceil(math.sqrt(columns_minus_one))\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], random_seed=SEED)\n",
    "name = f\"IGTD_{image_size}x{image_size}\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], zoom=2, random_seed=SEED)\n",
    "name = f\"IGTD_{image_size*2}x{image_size*2}\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], zoom=4, random_seed=SEED)\n",
    "name = f\"IGTD_{image_size*4}x{image_size*4}\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], fea_dist_method='Euclidean', image_dist_method='Euclidean', random_seed=SEED)\n",
    "name = f\"IGTD_{image_size}x{image_size}_fEuclidean_iEuclidean\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 3: REFINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = REFINED(problem= problem_type, random_seed=SEED)\n",
    "name = f\"REFINED\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = REFINED(problem= problem_type, zoom=2, random_seed=SEED)\n",
    "name = f\"REFINED_zoom2\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = REFINED(problem= problem_type, zoom=4, random_seed=SEED)\n",
    "name = f\"REFINED_zoom4\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 4: BAR GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = BarGraph(problem= problem_type)\n",
    "name = f\"BarGraph\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = BarGraph(problem= problem_type, zoom=2)\n",
    "name = f\"BarGraph_zoom2\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = BarGraph(problem= problem_type, zoom=4)\n",
    "name = f\"BarGraph_zoom4\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 5: DISTANCE MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = DistanceMatrix(problem= problem_type)\n",
    "name = f\"DistanceMatrix\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = DistanceMatrix(problem= problem_type, zoom=2)\n",
    "name = f\"DistanceMatrix_zoom2\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = DistanceMatrix(problem= problem_type, zoom=4)\n",
    "name = f\"DistanceMatrix_zoom4\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 6: COMBINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = Combination(problem= problem_type)\n",
    "name = f\"Combination\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = Combination(problem= problem_type, zoom=2)\n",
    "name = f\"Combination_zoom2\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = Combination(problem= problem_type, zoom=4)\n",
    "name = f\"Combination_zoom4\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 7: SUPERTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = SuperTML(problem= problem_type, random_seed=SEED)\n",
    "name = f\"SuperTML-EF\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = SuperTML(problem= problem_type, feature_importance=True, font_size=30, random_seed=SEED)\n",
    "name = f\"SuperTML-VF_FS30\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL METRICS AND BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(base_path):\n",
    "    best_accuracy = float('-inf')\n",
    "    best_folder = None\n",
    "\n",
    "    # Walk through all directories and files in the base path\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file == f'{dataset_name}_metrics.txt':\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Read metrics from the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    metrics = f.read()\n",
    "                \n",
    "                # Parse the metrics into a dictionary\n",
    "                metrics_dict = {}\n",
    "                for line in metrics.splitlines():\n",
    "                    key, value = line.split(': ')\n",
    "                    metrics_dict[key.strip()] = float(value.strip())\n",
    "                \n",
    "                # Check if the current folder has a better accuracy\n",
    "                if metrics_dict['test_accuracy'] > best_accuracy:\n",
    "                    best_accuracy = metrics_dict['test_accuracy']\n",
    "                    best_folder = root\n",
    "    \n",
    "    return best_folder, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_folder(old_folder_path):\n",
    "    # Extract the base name of the old folder\n",
    "    folder_name = os.path.basename(old_folder_path)\n",
    "    \n",
    "    # Create the new folder name by prepending \"best_\"\n",
    "    new_folder_name = f\"BEST_{folder_name}\"\n",
    "    \n",
    "    # Get the parent directory of the old folder\n",
    "    parent_dir = os.path.dirname(old_folder_path)\n",
    "    \n",
    "    # Create the full path for the new folder\n",
    "    new_folder_path = os.path.join(parent_dir, new_folder_name)\n",
    "    \n",
    "    # Rename the folder\n",
    "    os.rename(old_folder_path, new_folder_path)\n",
    "    \n",
    "    return new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model folder: logs/preprocessed_heloc/CNN+MLP_Binary\\BEST_TINTO_model2\n",
      "Best Accuracy: 0.7437974810600281\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "base_path = f\"logs/{dataset_name}/CNN+MLP_Binary\"\n",
    "best_folder, best_accuracy = find_best_model(base_path)\n",
    "best_folder = rename_folder(best_folder)\n",
    "print(f\"Best model folder: {best_folder}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tinto-HNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
