{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "#import openslide\n",
    "#from openslide.deepzoom import DeepZoomGenerator\n",
    "import tifffile as tifi\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,mean_absolute_percentage_error\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import vgg16, vgg19, resnet50, mobilenet, inception_resnet_v2, densenet, inception_v3, xception, nasnet, ResNet152V2\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, InputLayer, LayerNormalization\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.optimizers import SGD, Adam, Adadelta, Adamax\n",
    "from keras import layers, models, Model\n",
    "from keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from keras.layers import Input, Activation,MaxPooling2D, Concatenate, AveragePooling2D\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Models of TINTOlib\n",
    "from TINTOlib.tinto import TINTO\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.combination import Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 64\n",
    "\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable to store dataset name\n",
    "dataset_name = 'boston'\n",
    "results_path = f'logs/{dataset_name}/CNN_Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../Datasets_benchmark/Regression/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD AND PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_and_preprocess_data(images_folder, image_model, problem_type):\n",
    "\n",
    "    # Generate the images if the folder does not exist\n",
    "    if not os.path.exists(images_folder):\n",
    "        #Generate thet images\n",
    "        image_model.generateImages(df, images_folder)\n",
    "    else:\n",
    "        print(\"The images are already generated\")\n",
    "\n",
    "    img_paths = os.path.join(images_folder,problem_type+\".csv\")\n",
    "\n",
    "    print(img_paths)\n",
    "    \n",
    "    imgs = pd.read_csv(img_paths)\n",
    "\n",
    "    # Update image paths\n",
    "    imgs[\"images\"] = images_folder + \"/\" + imgs[\"images\"]\n",
    "\n",
    "    # Combine datasets\n",
    "    combined_dataset = pd.concat([imgs, df], axis=1)\n",
    "\n",
    "    # Split data\n",
    "    df_x = combined_dataset.drop(df.columns[-1], axis=1).drop(\"values\", axis=1)\n",
    "    df_y = combined_dataset[\"values\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size=0.20, random_state=SEED)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.50, random_state=SEED)\n",
    "\n",
    "    # Numerical data\n",
    "    X_train_num = X_train.drop(\"images\", axis=1)\n",
    "    X_val_num = X_val.drop(\"images\", axis=1)\n",
    "    X_test_num = X_test.drop(\"images\", axis=1)\n",
    "\n",
    "    # Image data\n",
    "    X_train_img = np.array([cv2.imread(img) for img in X_train[\"images\"]])\n",
    "    X_val_img = np.array([cv2.imread(img) for img in X_val[\"images\"]])\n",
    "    X_test_img = np.array([cv2.imread(img) for img in X_test[\"images\"]])\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Scale numerical data\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "    X_val_num = pd.DataFrame(scaler.transform(X_val_num), columns=X_val_num.columns)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(X_test_num), columns=X_test_num.columns)\n",
    "\n",
    "    attributes = len(X_train_num.columns)\n",
    "    imgs_shape = X_train_img[0].shape\n",
    "\n",
    "    print(\"Images shape: \",imgs_shape)\n",
    "    print(\"Attributres: \",attributes)\n",
    "    pixels=X_train_img[0].shape[0]\n",
    "    print(\"Image size (pixels):\", pixels)\n",
    "\n",
    "    return X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL ARCHITECTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small CNN for regression\n",
    "def create_model1(imgs_shape):\n",
    "    model1 = Sequential([\n",
    "        Input(shape=imgs_shape),\n",
    "        Conv2D(8, (3, 3), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='linear')  # Output layer for regression\n",
    "    ])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medium CNN\n",
    "def create_model2(imgs_shape):\n",
    "    model2 = Sequential([\n",
    "        Input(shape=imgs_shape),\n",
    "        Conv2D(16, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN with 2 branches\n",
    "\n",
    "def create_model3(cnn_input_shape):\n",
    "    # CNN branch\n",
    "    cnn_dropout = 0.1\n",
    "    cnn_input = Input(shape=cnn_input_shape)\n",
    "\n",
    "    # CNN branch 1\n",
    "    tower_1 = Conv2D(16, (3,3), activation='relu',padding=\"same\")(cnn_input)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(cnn_dropout)(tower_1)\n",
    "\n",
    "    tower_1 = Conv2D(32, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(cnn_dropout)(tower_1)\n",
    "\n",
    "    tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(cnn_dropout)(tower_1)\n",
    "\n",
    "    tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(cnn_dropout)(tower_1)\n",
    "\n",
    "    # CNN branch 2\n",
    "    tower_2 = Conv2D(16, (5,5), activation='relu',padding=\"same\")(cnn_input)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(cnn_dropout)(tower_2)\n",
    "\n",
    "    tower_2 = Conv2D(32, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(cnn_dropout)(tower_2)\n",
    "\n",
    "    tower_2 = Conv2D(64, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(cnn_dropout)(tower_2)\n",
    "\n",
    "    tower_2 = Conv2D(64, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(cnn_dropout)(tower_2)\n",
    "\n",
    "    #Concatenate CNN branches\n",
    "    merged_cnn = Concatenate(axis=1)([tower_1, tower_2])\n",
    "\n",
    "    #Flatten\n",
    "    merged = Flatten()(merged_cnn)\n",
    "\n",
    "    #Dense layers\n",
    "    out = Dense(256, activation='relu')(merged)\n",
    "    out = Dropout(cnn_dropout)(merged)\n",
    "    out = Dense(128, activation='sigmoid')(out)\n",
    "    out = Dropout(cnn_dropout)(out)\n",
    "    out = Dense(64, activation='sigmoid')(out)\n",
    "    out = Dropout(cnn_dropout)(out)\n",
    "    out = Dense(32, activation='sigmoid')(out)\n",
    "    out = Dropout(cnn_dropout)(out)\n",
    "    cnn_output = Dense(1, activation='linear')(out)\n",
    "\n",
    "    model3 = Model(cnn_input, cnn_output)\n",
    "\n",
    "    return model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    SS_res = K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    r2 = 1 - SS_res / (SS_tot + K.epsilon())\n",
    "    return r2\n",
    "\n",
    "METRICS = [\n",
    "    tf.keras.metrics.MeanSquaredError(name = 'mse'),\n",
    "    tf.keras.metrics.MeanAbsoluteError(name = 'mae'),\n",
    "    tf.keras.metrics.RootMeanSquaredError(name = 'rmse'),\n",
    "    r_square,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPILE AND FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, model_name, batch_size=32, epochs=200, lr=1e-3):\n",
    "\n",
    "    opt = Adam(learning_rate=lr)\n",
    "\n",
    "    # Define the early stopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',  # Monitor the validation loss\n",
    "        min_delta=0.001,     # Minimum change in the monitored quantity to qualify as an improvement\n",
    "        patience=20,          # Number of epochs with no improvement after which training will be stopped\n",
    "        verbose=1,           # Print messages when the callback takes an action\n",
    "        mode='min',           # Training will stop when the quantity monitored has stopped decreasing\n",
    "        restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "    )\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=opt,\n",
    "        metrics=METRICS\n",
    "    )\n",
    "\n",
    "    model_history = model.fit(\n",
    "        x=X_train_img, y=y_train,\n",
    "        validation_data=(X_val_img, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    os.makedirs(f\"models/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['loss'], color = 'red', label = 'loss')\n",
    "    plt.plot(model_history.history['val_loss'], color = 'green', label = 'val loss')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/loss_plot.png\")\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['mse'], color = 'red', label = 'mse')\n",
    "    plt.plot(model_history.history['val_mse'], color = 'green', label = 'val mse')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/mse_plot.png\")\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['rmse'], color = 'red', label = 'rmse')\n",
    "    plt.plot(model_history.history['val_rmse'], color = 'green', label = 'val rmse')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/rmse_plot.png\")\n",
    "\n",
    "    # Save the model\n",
    "    os.makedirs(f\"models/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "    model.save(f\"models/{dataset_name}/{model_name}/model_{dataset_name}.keras\")\n",
    "\n",
    "    # Evaluate the model on the training set\n",
    "    train_scores = model.evaluate(X_train_img, y_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_scores = model.evaluate(X_val_img, y_val)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    score_test = model.evaluate(X_test_img, y_test)\n",
    "\n",
    "    # Save training, validation, and test scores\n",
    "    metrics = {\n",
    "        'train_loss': train_scores[0],\n",
    "        'train_mse': train_scores[1],\n",
    "        'train_mae': train_scores[2],\n",
    "        'train_rmse': train_scores[3],\n",
    "        'train_r2': train_scores[4],\n",
    "        'val_loss': val_scores[0],\n",
    "        'val_mse': val_scores[1],\n",
    "        'val_mae': val_scores[2],\n",
    "        'val_rmse': val_scores[3],\n",
    "        'val_r2': val_scores[4],\n",
    "        'test_loss': score_test[0],\n",
    "        'test_mse': score_test[1],\n",
    "        'test_mae': score_test[2],\n",
    "        'test_rmse': score_test[3],\n",
    "        'test_r2': score_test[4]\n",
    "    }\n",
    "\n",
    "    # Save metrics to a file\n",
    "    os.makedirs(f'{results_path}/{model_name}', exist_ok=True)\n",
    "    with open(f'{results_path}/{model_name}/{dataset_name}_metrics.txt', 'w') as f:\n",
    "        for key, value in metrics.items():\n",
    "            f.write(f'{key}: {value}\\n')\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test,dataset_name, model_name, batch_size=32, epochs=200, lr=1e-3):\n",
    "    try:\n",
    "        if model is None:\n",
    "            print(f\"Model {model_name} is None\")\n",
    "            return None\n",
    "        else:\n",
    "            metrics = compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test,dataset_name, model_name, batch_size, epochs, lr)\n",
    "            return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to compile and fit {model_name}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_create_model(create_model_func, imgs_shape):\n",
    "    try:\n",
    "        model = create_model_func(imgs_shape)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "#image_model = REFINED(problem= problem_type,hcIterations=5)\n",
    "image_model = TINTO(problem= problem_type, blur=True)\n",
    "#image_model = IGTD(problem= problem_type)\n",
    "#image_model = BarGraph(problem= problem_type)\n",
    "#image_model = DistanceMatrix(problem= problem_type)\n",
    "#image_model = Combination(problem= problem_type)\n",
    "#image_model = SuperTML(problem= problem_type)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_IGTD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, blur=True)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_TINTO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are already generated\n",
      "../HyNNImages/Regression/boston/images_boston_TINTO\\regression.csv\n",
      "Images shape:  (20, 20, 3)\n",
      "Attributres:  13\n",
      "Image size (pixels): 20\n"
     ]
    }
   ],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape)\n",
    "model2 = try_create_model(create_model2, imgs_shape)\n",
    "model3 = try_create_model(create_model3, imgs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"TINTO_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"TINTO_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"TINTO_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "pixel = 20\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[4,4])\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_IGTD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are already generated\n",
      "../HyNNImages/Regression/boston/images_boston_IGTD\\regression.csv\n",
      "Images shape:  (4, 4, 3)\n",
      "Attributres:  13\n",
      "Image size (pixels): 4\n"
     ]
    }
   ],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_create_model(create_model_func, imgs_shape):\n",
    "    try:\n",
    "        model = create_model_func(imgs_shape)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating model: Computed output size would be negative. Received `inputs shape=(None, 1, 1, 16)`, `kernel shape=(3, 3, 16, 32)`, `dilation_rate=[1 1]`.\n"
     ]
    }
   ],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape)\n",
    "model2 = try_create_model(create_model2, imgs_shape)\n",
    "model3 = try_create_model(create_model3, imgs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"IGTD_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"IGTD_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"IGTD_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = Combination(problem= problem_type, zoom=4)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_Combination_zoom4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are already generated\n",
      "../HyNNImages/Regression/boston/images_boston_Combination_zoom4\\regression.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape:  (52, 52, 3)\n",
      "Attributres:  13\n",
      "Image size (pixels): 52\n"
     ]
    }
   ],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 52, 52, 3)\n"
     ]
    }
   ],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape)\n",
    "model2 = try_create_model(create_model2, imgs_shape)\n",
    "model3 = try_create_model(create_model3, imgs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"Combination_zoom4_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"Combination_zoom4_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"Combination_zoom4_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(base_path):\n",
    "    best_rmse = float('inf')\n",
    "    best_folder = None\n",
    "\n",
    "    # Walk through all directories and files in the base path\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file == f'{dataset_name}_metrics.txt':\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Read metrics from the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    metrics = f.read()\n",
    "                \n",
    "                # Parse the metrics into a dictionary\n",
    "                metrics_dict = {}\n",
    "                for line in metrics.splitlines():\n",
    "                    key, value = line.split(': ')\n",
    "                    metrics_dict[key.strip()] = float(value.strip())\n",
    "                \n",
    "                # Check if the current folder has a better validation loss\n",
    "                if metrics_dict['test_rmse'] < best_rmse:\n",
    "                    best_rmse = metrics_dict['test_rmse']\n",
    "                    best_folder = root\n",
    "    \n",
    "    return best_folder, best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_folder(old_folder_path):\n",
    "    # Extract the base name of the old folder\n",
    "    folder_name = os.path.basename(old_folder_path)\n",
    "    \n",
    "    # Create the new folder name by prepending \"best_\"\n",
    "    new_folder_name = f\"BEST_{folder_name}\"\n",
    "    \n",
    "    # Get the parent directory of the old folder\n",
    "    parent_dir = os.path.dirname(old_folder_path)\n",
    "    \n",
    "    # Create the full path for the new folder\n",
    "    new_folder_path = os.path.join(parent_dir, new_folder_name)\n",
    "    \n",
    "    # Rename the folder\n",
    "    os.rename(old_folder_path, new_folder_path)\n",
    "    \n",
    "    return new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model folder: logs/boston/CNN_Regression\\BEST_BEST_TINTO_Model2\n",
      "Best RMSE: 2.8623054027557373\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "base_path = f\"logs/{dataset_name}/CNN_Regression\"\n",
    "best_folder, best_rmse = find_best_model(base_path)\n",
    "best_folder = rename_folder(best_folder)\n",
    "print(f\"Best model folder: {best_folder}\")\n",
    "print(f\"Best RMSE: {best_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tinto-HNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
