{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "#import openslide\n",
    "#from openslide.deepzoom import DeepZoomGenerator\n",
    "import tifffile as tifi\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,mean_absolute_percentage_error\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import vgg16, vgg19, resnet50, mobilenet, inception_resnet_v2, densenet, inception_v3, xception, nasnet, ResNet152V2\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, InputLayer, LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, Adamax\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from tensorflow.keras.layers import Input, Activation,MaxPooling2D, Concatenate, AveragePooling2D\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Models of TINTOlib\n",
    "from TINTOlib.tinto import TINTO\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.combination import Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 64\n",
    "\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable to store dataset name\n",
    "dataset_name = 'california_housing'\n",
    "results_path = f'logs/{dataset_name}/CNN_Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../Datasets_benchmark/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD AND PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_and_preprocess_data(images_folder, image_model, problem_type):\n",
    "\n",
    "    # Generate the images if the folder does not exist\n",
    "    if not os.path.exists(images_folder):\n",
    "        #Generate thet images\n",
    "        image_model.generateImages(df, images_folder)\n",
    "    else:\n",
    "        print(\"The images are already generated\")\n",
    "\n",
    "    img_paths = os.path.join(images_folder,problem_type+\".csv\")\n",
    "\n",
    "    print(img_paths)\n",
    "    \n",
    "    imgs = pd.read_csv(img_paths)\n",
    "\n",
    "    # Update image paths\n",
    "    imgs[\"images\"] = images_folder + \"/\" + imgs[\"images\"]\n",
    "\n",
    "    # Combine datasets\n",
    "    combined_dataset = pd.concat([imgs, df], axis=1)\n",
    "\n",
    "    # Split data\n",
    "    df_x = combined_dataset.drop(df.columns[-1], axis=1).drop(\"values\", axis=1)\n",
    "    df_y = combined_dataset[\"values\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size=0.40, random_state=123)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.50, random_state=123)\n",
    "\n",
    "    # Numerical data\n",
    "    X_train_num = X_train.drop(\"images\", axis=1)\n",
    "    X_val_num = X_val.drop(\"images\", axis=1)\n",
    "    X_test_num = X_test.drop(\"images\", axis=1)\n",
    "\n",
    "    # Image data\n",
    "    X_train_img = np.array([cv2.imread(img) for img in X_train[\"images\"]])\n",
    "    X_val_img = np.array([cv2.imread(img) for img in X_val[\"images\"]])\n",
    "    X_test_img = np.array([cv2.imread(img) for img in X_test[\"images\"]])\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Scale numerical data\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "    X_val_num = pd.DataFrame(scaler.transform(X_val_num), columns=X_val_num.columns)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(X_test_num), columns=X_test_num.columns)\n",
    "\n",
    "    attributes = len(X_train_num.columns)\n",
    "    imgs_shape = X_train_img[0].shape\n",
    "\n",
    "    print(\"Images shape: \",imgs_shape)\n",
    "    print(\"Attributres: \",attributes)\n",
    "    pixels=X_train_img[0].shape[0]\n",
    "    print(\"Image size (pixels):\", pixels)\n",
    "\n",
    "    return X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL ARCHITECTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "# This represents the number of filters or output channels in the convolutional layer.\n",
    "def create_model1(imgs_shape):\n",
    "    model1 = Sequential([\n",
    "        Input(shape=imgs_shape),\n",
    "        Conv2D(4, (2, 2), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1)  # Output layer for regression\n",
    "    ])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN big\n",
    "def create_model2(imgs_shape):\n",
    "    model2 = Sequential([\n",
    "        Input(shape=imgs_shape),\n",
    "        Conv2D(16, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input\n",
    "\n",
    "def create_model3(imgs_shape):\n",
    "    input_shape = Input(shape=imgs_shape)\n",
    "\n",
    "    dropout = 0.1\n",
    "\n",
    "    # CNN branch 1\n",
    "    tower_1 = Conv2D(16, (3,3), activation='relu',padding=\"same\")(input_shape)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "    tower_1 = Conv2D(32, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "    tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "    #tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "    #tower_1 = BatchNormalization()(tower_1)\n",
    "    #tower_1 = Activation('relu')(tower_1)\n",
    "    #tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    #tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "    #CNN branch 2\n",
    "    tower_2 = Conv2D(16, (5,5), activation='relu',padding=\"same\")(input_shape)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "    tower_2 = Conv2D(32, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "    tower_2 = Conv2D(64, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "    #tower_2 = Conv2D(64, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "    #tower_2 = BatchNormalization()(tower_2)\n",
    "    #tower_2 = Activation('relu')(tower_2)\n",
    "    #tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    #tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "    #Concatenate CNN branches\n",
    "    merged = Concatenate(axis=1)([tower_1, tower_2])\n",
    "\n",
    "    #Flatten\n",
    "    merged = Flatten()(merged)\n",
    "\n",
    "    #Dense layers\n",
    "    out = Dense(256, activation='relu')(merged)\n",
    "    out = Dropout(dropout)(merged)\n",
    "    out = Dense(128, activation='relu')(out)\n",
    "    out = Dropout(dropout)(out)\n",
    "    out = Dense(64, activation='relu')(out)\n",
    "    out = Dropout(dropout)(out)\n",
    "    out = Dense(32, activation='relu')(out)\n",
    "    out = Dropout(dropout)(out)\n",
    "    out = Dense(1, activation='relu')(out)\n",
    "\n",
    "    model3 = Model(input_shape, out)\n",
    "\n",
    "    return model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    SS_res = K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    r2 = 1 - SS_res / (SS_tot + K.epsilon())\n",
    "    return r2\n",
    "\n",
    "METRICS = [\n",
    "    tf.keras.metrics.MeanSquaredError(name = 'mse'),\n",
    "    tf.keras.metrics.MeanAbsoluteError(name = 'mae'),\n",
    "    tf.keras.metrics.RootMeanSquaredError(name = 'rmse'),\n",
    "    r_square,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPILE AND FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def compile_and_fit(model, X_train, y_train, X_val, y_val, X_test, y_test,dataset_name, model_name):\n",
    "\n",
    "    opt = Adam(learning_rate=1e-3)\n",
    "\n",
    "    # Define the early stopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',  # Monitor the validation loss\n",
    "        min_delta=0.001,     # Minimum change in the monitored quantity to qualify as an improvement\n",
    "        patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "        verbose=1,           # Print messages when the callback takes an action\n",
    "        mode='min'           # Training will stop when the quantity monitored has stopped decreasing\n",
    "    )\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=opt,\n",
    "        metrics=METRICS\n",
    "    )\n",
    "\n",
    "    model_history = model.fit(\n",
    "        x=X_train, y=y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    os.makedirs(f\"models/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "\n",
    "    plt.plot(model_history.history['loss'], color = 'red', label = 'loss')\n",
    "    plt.plot(model_history.history['val_loss'], color = 'green', label = 'val loss')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/loss_plot.png\")\n",
    "\n",
    "    plt.plot(model_history.history['mse'], color = 'red', label = 'mse')\n",
    "    plt.plot(model_history.history['val_mse'], color = 'green', label = 'val mse')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/mse_plot.png\")\n",
    "\n",
    "    # Save the model\n",
    "    os.makedirs(f\"models/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "    model.save(f\"models/{dataset_name}/{model_name}/model_{dataset_name}.keras\")\n",
    "\n",
    "    # Evaluate the model on the training set\n",
    "    train_scores = model.evaluate(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_scores = model.evaluate(X_val, y_val)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    score_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "    # Save training, validation, and test scores\n",
    "    metrics = {\n",
    "        'train_loss': train_scores[0],\n",
    "        'train_mse': train_scores[1],\n",
    "        'train_mae': train_scores[2],\n",
    "        'train_rmse': train_scores[3],\n",
    "        'train_r2': train_scores[4],\n",
    "        'val_loss': val_scores[0],\n",
    "        'val_mse': val_scores[1],\n",
    "        'val_mae': val_scores[2],\n",
    "        'val_rmse': val_scores[3],\n",
    "        'val_r2': val_scores[4],\n",
    "        'test_loss': score_test[0],\n",
    "        'test_mse': score_test[1],\n",
    "        'test_mae': score_test[2],\n",
    "        'test_rmse': score_test[3],\n",
    "        'test_r2': score_test[4]\n",
    "    }\n",
    "\n",
    "    # Save metrics to a file\n",
    "    os.makedirs(f'{results_path}/{model_name}', exist_ok=True)\n",
    "    with open(f'{results_path}/{model_name}/{dataset_name}_metrics.txt', 'w') as f:\n",
    "        for key, value in metrics.items():\n",
    "            f.write(f'{key}: {value}\\n')\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "pixel = 20\n",
    "problem_type = \"regression\"\n",
    "image_model = REFINED(problem= problem_type,hcIterations=5)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/images_{dataset_name}_REFINED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are already generated\n",
      "../HyNNImages/Regression/images_california_housing_REFINED\\regression.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape:  (3, 3, 3)\n",
      "Attributres:  8\n",
      "Image size (pixels): 3\n"
     ]
    }
   ],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"sequential_3\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=3>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jiayu\\anaconda3\\envs\\HNNTinto\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\jiayu\\anaconda3\\envs\\HNNTinto\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py:219\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    214\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs to a layer should be tensors. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) as input for layer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[1;32m--> 219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m     )\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_index, (x, spec) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(inputs, input_spec)):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Layer \"sequential_3\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=3>]"
     ]
    }
   ],
   "source": [
    "model1 = create_model1(imgs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with two models\n",
    "model1_metrics = compile_and_fit(model1, X_train_img, y_train, X_val_img, y_val, X_test_img, y_test, dataset_name, \"Model1\")\n",
    "# Print comparison of metrics\n",
    "print(\"Model 1 Metrics:\", model1_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tinto-HNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
