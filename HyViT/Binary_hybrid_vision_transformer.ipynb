{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EybOZ6hSjpCF"
   },
   "source": [
    "<h1><font color=\"#113D68\" size=6>TINTOlib: Converting Tidy Data into Image for Hybrid Neural Networks (HyNN)</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=5>Template Binary Classification Machine Learning problem with a Hybrid Vision Transformer (ViT+MLP)</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#113D68\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#113D68\" size=3>Raúl García-Castro</font><br>\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l5nFzsdjpCW"
   },
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Index</font></h2>\n",
    "\n",
    "* [0. Context](#section0)\n",
    "* [1. Description](#section1)\n",
    "    * [1.1. Main Features](#section11)\n",
    "    * [1.2. Citation](#section12)\n",
    "    * [1.3. Documentation and License](#section13)\n",
    "* [2. Libraries](#section2)\n",
    "    * [2.1. System setup](#section21)\n",
    "    * [2.2. Invoke the libraries](#section22)\n",
    "* [3. Data processing](#section3)\n",
    "    * [3.1. TINTOlib methods](#section31)\n",
    "    * [3.2. Read the dataset](#section32)\n",
    "    * [3.3. Generate images](#section33)\n",
    "    * [3.4. Read images](#section34)\n",
    "    * [3.5. Mix images and tidy data](#section35)\n",
    "* [4. Pre-modelling phase](#section4)\n",
    "    * [4.1. Data curation](#section41)\n",
    "    * [4.2. One-hot encoding](#section42)\n",
    "* [5. Modelling hybrid network](#section5)\n",
    "    * [5.1. FFNN for tabular data](#section51)\n",
    "    * [5.2. CNN for TINTOlib images](#section52)\n",
    "    * [5.3. Concatenate branches](#section53)\n",
    "    * [5.4. Metrics](#section54)\n",
    "    * [5.5. Compile and fit](#section55)\n",
    "* [6. Results](#section6)\n",
    "    * [6.1. Train/Validation representation](#section61)\n",
    "    * [6.2. Validation/Test evaluation](#section62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxTpMExHjpCa"
   },
   "source": [
    "---\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 0. Context</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlVYt3MRrl_V"
   },
   "source": [
    "This is a tutorial on how to read the images created by TINTOlib and pass them to a Vision Transformer (ViT). The images must already be created by the TINTOlib software. See the documentation in GITHUB for how to create the images from tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3tgsO0BjpCj"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib code in [GitHub](https://github.com/oeg-upm/TINTOlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3tgsO0BjpCj"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib documentation in [PyPI](https://tintolib.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RKBgDwzjpCl"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpU7pi6yjpCn"
   },
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 1. Description</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NL9RoFkEjpCq"
   },
   "source": [
    "The growing interest in the use of algorithms-based machine learning for predictive tasks has generated a large and diverse development of algorithms. However, it is widely known that not all of these algorithms are adapted to efficient solutions in certain tidy data format datasets. For this reason, novel techniques are currently being developed to convert tidy data into images with the aim of using Convolutional Neural Networks (CNNs) or Vision Transformer (ViT). TINTOlib offers the opportunity to convert tidy data into images through several techniques: TINTO, IGTD, REFINED, SuperTML, BarGraph, DistanceMatrix and Combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFrF4C89jpCt"
   },
   "source": [
    "---\n",
    "<a id=\"section11\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 1.1. Main Features</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gruE0_sjpCu"
   },
   "source": [
    "- Supports all CSV data in **[Tidy Data](https://www.jstatsoft.org/article/view/v059i10)** format.\n",
    "- For now, the algorithm converts tabular data for binary and multi-class classification problems into machine learning.\n",
    "- Input data formats:\n",
    "    - **Tabular files**: The input data could be in **[CSV](https://en.wikipedia.org/wiki/Comma-separated_values)**, taking into account the **[Tidy Data](https://www.jstatsoft.org/article/view/v059i10)** format.\n",
    "    - **Dataframe***: The input data could be in **[Pandas Dataframe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)**, taking into account the **[Tidy Data](https://www.jstatsoft.org/article/view/v059i10)** format.\n",
    "    - **Tidy Data**: The **target** (variable to be predicted) should be set as the last column of the dataset. Therefore, the first columns will be the features.\n",
    "    - All data must be in numerical form. TINTOlib does not accept data in string or any other non-numeric format.\n",
    "- Runs on **Linux**, **Windows** and **macOS** systems.\n",
    "- Compatible with **[Python](https://www.python.org/)** 3.7 or higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section12\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 1.2. Citation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TINTOlib** is an python library that makes **Synthetic Images** from [Tidy Data](https://www.jstatsoft.org/article/view/v059i10) (also knows as **Tabular Data**).\n",
    "\n",
    "**Citing TINTO**: If you used TINTO in your work, please cite the **[SoftwareX](https://doi.org/10.1016/j.softx.2023.101391)**:\n",
    "\n",
    "```bib\n",
    "@article{softwarex_TINTO,\n",
    "    title = {TINTO: Converting Tidy Data into Image for Classification\n",
    "            with 2-Dimensional Convolutional Neural Networks},\n",
    "    journal = {SoftwareX},\n",
    "    author = {Manuel Castillo-Cara and Reewos Talla-Chumpitaz and\n",
    "              Raúl García-Castro and Luis Orozco-Barbosa},\n",
    "    year = {2023},\n",
    "    pages = {101391},\n",
    "    issn = {2352-7110},\n",
    "    doi = {https://doi.org/10.1016/j.softx.2023.101391}\n",
    "}\n",
    "```\n",
    "\n",
    "And use-case developed in **[INFFUS Paper](https://doi.org/10.1016/j.inffus.2022.10.011)**\n",
    "\n",
    "```bib\n",
    "@article{inffus_TINTO,\n",
    "    title = {A novel deep learning approach using blurring image\n",
    "            techniques for Bluetooth-based indoor localisation},\n",
    "    journal = {Information Fusion},\n",
    "    author = {Reewos Talla-Chumpitaz and Manuel Castillo-Cara and\n",
    "              Luis Orozco-Barbosa and Raúl García-Castro},\n",
    "    volume = {91},\n",
    "    pages = {173-186},\n",
    "    year = {2023},\n",
    "    issn = {1566-2535},\n",
    "    doi = {https://doi.org/10.1016/j.inffus.2022.10.011}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section13\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 1.3. Documentation and License</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TINTOlib has a wide range of documentation on both GitHub and PiPY. \n",
    "\n",
    "Moreover, TINTOlib is free and open software with Apache 2.0 license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3tgsO0BjpCj"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib code in [GitHub](https://github.com/oeg-upm/TINTOlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3tgsO0BjpCj"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib documentation in [PyPI](https://tintolib.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3EzYcjJjpC6"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwYF5A2njpC8"
   },
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 2. Libraries</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section21\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 2.1. System setup</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before installing the libraries you must have the `mpi4py` package installed on the native (Linux) system. This link shows how to install it: \n",
    "- Link: [`mpi4py` in Linux](https://www.geeksforgeeks.org/how-to-install-python3-mpi4py-package-on-linux/)\n",
    "\n",
    "For example, in Linux:\n",
    "\n",
    "```\n",
    "    sudo apt-get install python3\n",
    "    sudo apt install python3-pip\n",
    "    sudo apt install python3-mpi4py\n",
    "```\n",
    "\n",
    "If you are in Windows, Mac or, also, Linux, you can install from PyPI if you want:\n",
    "```\n",
    "    sudo pip3 install mpi4py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Note that you must **restart the kernel or the system** so that it can load the libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, once you have installed `mpi4py` you can install the PyPI libraries and dependences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (1.3.0.post0)\n",
      "Requirement already satisfied: pytorch_lightning in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: TINTOlib in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (0.0.17)\n",
      "Requirement already satisfied: imblearn in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: keras_preprocessing in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: mpi4py in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from torchmetrics) (1.24.3)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from torchmetrics) (2.2.0+cu118)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from torchmetrics) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\jiayu\\appdata\\roaming\\python\\python311\\site-packages (from pytorch_lightning) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from pytorch_lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from pytorch_lightning) (4.8.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from imblearn) (0.12.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from keras_preprocessing) (1.16.0)\n",
      "Requirement already satisfied: requests in c:\\users\\jiayu\\appdata\\roaming\\python\\python311\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\jiayu\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.57.0->pytorch_lightning) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\jiayu\\appdata\\roaming\\python\\python311\\site-packages (from imbalanced-learn->imblearn) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from imbalanced-learn->imblearn) (3.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jiayu\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jiayu\\appdata\\roaming\\python\\python311\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jiayu\\appdata\\roaming\\python\\python311\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: pydot in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\jiayu\\anaconda3\\envs\\tinto-hnn\\lib\\site-packages (from pydot) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics pytorch_lightning TINTOlib imblearn keras_preprocessing mpi4py\n",
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Note that you must **restart the kernel** so that it can load the libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section22\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 2.2. Invoke the libraries</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding parent directory to import module residing outside this notebook folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AdHKnWYsEq_"
   },
   "source": [
    "The first thing we need to do is to declare the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PeeBbGxlpjFp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tifffile as tifi\n",
    "import keras\n",
    "from keras import ops\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (mean_absolute_error, mean_absolute_percentage_error,\n",
    "                             mean_squared_error, r2_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# TensorFlow and Keras\n",
    "from keras import layers, models, Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import (Activation, BatchNormalization, concatenate,\n",
    "                                     Conv2D, Dense, Dropout, Flatten, Input,\n",
    "                                     LayerNormalization, MaxPool2D, MaxPooling2D)\n",
    "from keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adadelta, Adam, Adamax, SGD\n",
    "\n",
    "# TINTOlib Models\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.combination import Combination\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.tinto import TINTO\n",
    "\n",
    "# Set the backend for Keras\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # @param [\"tensorflow\", \"jax\", \"torch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwS-cKUxjpDQ"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDL4LARWjpDT"
   },
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 3. Data processing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXcRw78ljpDU"
   },
   "source": [
    "The first thing to do is to read all the images created by TINTO. TINTO creates a folder which contains subfolders corresponding to each target that has the problem. Each image corresponds to a sample of the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section31\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.1. TINTOlib methods</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the declaration of the classes with the TINTOlib method we want to transform. Note that TINTOlib has several methods and we will have to choose one of them since each method generates different images.\n",
    "\n",
    "In addition, we establish the paths where the dataset is located and also the folder where the images will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 64\n",
    "\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "#torch.manual_seed(SEED)\n",
    "#torch.cuda.manual_seed(SEED)\n",
    "#torch.cuda.manual_seed_all(SEED)\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"supervised\"\n",
    "pixel = 20\n",
    "image_model = REFINED(problem= problem_type,hcIterations=5, random_seed=SEED, scale_up=False)\n",
    "#image_model = TINTO(problem= problem_type,blur=True)\n",
    "#image_model = IGTD(problem= problem_type)\n",
    "#image_model = BarGraph(problem= problem_type)\n",
    "#image_model = DistanceMatrix(problem= problem_type)\n",
    "#image_model = Combination(problem= problem_type)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "results_folder = \"./results_heloc_TINTO_1\"\n",
    "dataset_path = \"../Datasets/heloc.csv\"\n",
    "images_folder = \"../HyNNImages/Classification/heloc_REFINED\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all TINTOlib method in the [PyPI documentation](https://tintolib.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section32\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.2. Read the dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we proceed to read the dataset according to the path specified above and also standardize the name that the target will have, in this case, it will be called `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RiskPerformance</th>\n",
       "      <th>ExternalRiskEstimate</th>\n",
       "      <th>MSinceOldestTradeOpen</th>\n",
       "      <th>MSinceMostRecentTradeOpen</th>\n",
       "      <th>AverageMInFile</th>\n",
       "      <th>NumSatisfactoryTrades</th>\n",
       "      <th>NumTrades60Ever2DerogPubRec</th>\n",
       "      <th>NumTrades90Ever2DerogPubRec</th>\n",
       "      <th>PercentTradesNeverDelq</th>\n",
       "      <th>MSinceMostRecentDelq</th>\n",
       "      <th>...</th>\n",
       "      <th>PercentInstallTrades</th>\n",
       "      <th>MSinceMostRecentInqexcl7days</th>\n",
       "      <th>NumInqLast6M</th>\n",
       "      <th>NumInqLast6Mexcl7days</th>\n",
       "      <th>NetFractionRevolvingBurden</th>\n",
       "      <th>NetFractionInstallBurden</th>\n",
       "      <th>NumRevolvingTradesWBalance</th>\n",
       "      <th>NumInstallTradesWBalance</th>\n",
       "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
       "      <th>PercentTradesWBalance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad</td>\n",
       "      <td>55</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>-8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>-7</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RiskPerformance  ExternalRiskEstimate  MSinceOldestTradeOpen  \\\n",
       "0             Bad                    55                    144   \n",
       "1             Bad                    61                     58   \n",
       "\n",
       "   MSinceMostRecentTradeOpen  AverageMInFile  NumSatisfactoryTrades  \\\n",
       "0                          4              84                     20   \n",
       "1                         15              41                      2   \n",
       "\n",
       "   NumTrades60Ever2DerogPubRec  NumTrades90Ever2DerogPubRec  \\\n",
       "0                            3                            0   \n",
       "1                            4                            4   \n",
       "\n",
       "   PercentTradesNeverDelq  MSinceMostRecentDelq  ...  PercentInstallTrades  \\\n",
       "0                      83                     2  ...                    43   \n",
       "1                     100                    -7  ...                    67   \n",
       "\n",
       "   MSinceMostRecentInqexcl7days  NumInqLast6M  NumInqLast6Mexcl7days  \\\n",
       "0                             0             0                      0   \n",
       "1                             0             0                      0   \n",
       "\n",
       "   NetFractionRevolvingBurden  NetFractionInstallBurden  \\\n",
       "0                          33                        -8   \n",
       "1                           0                        -8   \n",
       "\n",
       "   NumRevolvingTradesWBalance  NumInstallTradesWBalance  \\\n",
       "0                           8                         1   \n",
       "1                           0                        -8   \n",
       "\n",
       "   NumBank2NatlTradesWHighUtilization  PercentTradesWBalance  \n",
       "0                                   1                     69  \n",
       "1                                  -8                      0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read CSV\n",
    "df = pd.read_csv(dataset_path)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10459, 24)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['RiskPerformance'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "print(\"Categorical columns:\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select the first column\n",
    "first_column = df.iloc[:, 0]\n",
    "\n",
    "# Step 2: Drop the first column from the dataframe\n",
    "df = df.iloc[:, 1:]\n",
    "\n",
    "# Step 3: Append the first column to the end of the dataframe\n",
    "df[first_column.name] = first_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ExternalRiskEstimate', 'MSinceOldestTradeOpen',\n",
       "       'MSinceMostRecentTradeOpen', 'AverageMInFile', 'NumSatisfactoryTrades',\n",
       "       'NumTrades60Ever2DerogPubRec', 'NumTrades90Ever2DerogPubRec',\n",
       "       'PercentTradesNeverDelq', 'MSinceMostRecentDelq',\n",
       "       'MaxDelq2PublicRecLast12M', 'MaxDelqEver', 'NumTotalTrades',\n",
       "       'NumTradesOpeninLast12M', 'PercentInstallTrades',\n",
       "       'MSinceMostRecentInqexcl7days', 'NumInqLast6M', 'NumInqLast6Mexcl7days',\n",
       "       'NetFractionRevolvingBurden', 'NetFractionInstallBurden',\n",
       "       'NumRevolvingTradesWBalance', 'NumInstallTradesWBalance',\n",
       "       'NumBank2NatlTradesWHighUtilization', 'PercentTradesWBalance',\n",
       "       'RiskPerformance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExternalRiskEstimate</th>\n",
       "      <th>MSinceOldestTradeOpen</th>\n",
       "      <th>MSinceMostRecentTradeOpen</th>\n",
       "      <th>AverageMInFile</th>\n",
       "      <th>NumSatisfactoryTrades</th>\n",
       "      <th>NumTrades60Ever2DerogPubRec</th>\n",
       "      <th>NumTrades90Ever2DerogPubRec</th>\n",
       "      <th>PercentTradesNeverDelq</th>\n",
       "      <th>MSinceMostRecentDelq</th>\n",
       "      <th>MaxDelq2PublicRecLast12M</th>\n",
       "      <th>...</th>\n",
       "      <th>MSinceMostRecentInqexcl7days</th>\n",
       "      <th>NumInqLast6M</th>\n",
       "      <th>NumInqLast6Mexcl7days</th>\n",
       "      <th>NetFractionRevolvingBurden</th>\n",
       "      <th>NetFractionInstallBurden</th>\n",
       "      <th>NumRevolvingTradesWBalance</th>\n",
       "      <th>NumInstallTradesWBalance</th>\n",
       "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
       "      <th>PercentTradesWBalance</th>\n",
       "      <th>RiskPerformance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.188424</td>\n",
       "      <td>0.033163</td>\n",
       "      <td>0.237245</td>\n",
       "      <td>0.329545</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.844037</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.174274</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.31250</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.082512</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.127551</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.037344</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExternalRiskEstimate  MSinceOldestTradeOpen  MSinceMostRecentTradeOpen  \\\n",
       "0              0.621359               0.188424                   0.033163   \n",
       "1              0.679612               0.082512                   0.061224   \n",
       "\n",
       "   AverageMInFile  NumSatisfactoryTrades  NumTrades60Ever2DerogPubRec  \\\n",
       "0        0.237245               0.329545                     0.428571   \n",
       "1        0.127551               0.125000                     0.464286   \n",
       "\n",
       "   NumTrades90Ever2DerogPubRec  PercentTradesNeverDelq  MSinceMostRecentDelq  \\\n",
       "0                     0.321429                0.844037              0.119565   \n",
       "1                     0.464286                1.000000              0.021739   \n",
       "\n",
       "   MaxDelq2PublicRecLast12M  ...  MSinceMostRecentInqexcl7days  NumInqLast6M  \\\n",
       "0                  0.666667  ...                      0.272727          0.12   \n",
       "1                  0.500000  ...                      0.272727          0.12   \n",
       "\n",
       "   NumInqLast6Mexcl7days  NetFractionRevolvingBurden  \\\n",
       "0                   0.12                    0.174274   \n",
       "1                   0.12                    0.037344   \n",
       "\n",
       "   NetFractionInstallBurden  NumRevolvingTradesWBalance  \\\n",
       "0                  0.002083                    0.414634   \n",
       "1                  0.002083                    0.219512   \n",
       "\n",
       "   NumInstallTradesWBalance  NumBank2NatlTradesWHighUtilization  \\\n",
       "0                   0.31250                            0.370370   \n",
       "1                   0.03125                            0.037037   \n",
       "\n",
       "   PercentTradesWBalance  RiskPerformance  \n",
       "0               0.715596              Bad  \n",
       "1               0.082569              Bad  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all the attributes to normalize\n",
    "columns_to_normalize = df.columns[:-1]\n",
    "\n",
    "# Normalize between 0 and 1\n",
    "df_normalized = (df[columns_to_normalize] - df[columns_to_normalize].min()) / (df[columns_to_normalize].max() - df[columns_to_normalize].min())\n",
    "\n",
    "# Combine the attributes and the label\n",
    "df_normalized = pd.concat([df_normalized, df[df.columns[-1]]], axis=1)\n",
    "\n",
    "df_normalized.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section33\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.3. Generate images</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate the images with the `generateImages()` generic function. Likewise, we create a dataset that will have the path of each of the samples with the corresponding image created for it. \n",
    "\n",
    "Note that each image is created based on a row, therefore, each numerical sample of the dataset will correspond to a particular image. In other words, we will have the same number of images as samples/rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING\n",
      "../HyNNImages/Classification/heloc_REFINED\\supervised.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Generate the images if the folder does not exist\n",
    "if not os.path.exists(images_folder):\n",
    "    #Generate thet images\n",
    "    image_model.generateImages(df, images_folder)\n",
    "else:\n",
    "    print(\"The images are already generated\")\n",
    "\n",
    "img_paths = os.path.join(images_folder,problem_type+\".csv\")\n",
    "\n",
    "print(img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section34\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.4. Read Images</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we read the created images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = pd.read_csv(img_paths)\n",
    "\n",
    "#imgs[\"images\"]= images_folder + \"\\\\\" + imgs[\"images\"]\n",
    "imgs[\"images\"]= images_folder + \"/\" + imgs[\"images\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section35\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.5. Mix images and tidy data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are going to use hybrid networks, i.e. create a model in which we join a ViT for the images and a MLP for the tabular data, we are going to join it in order to integrate all the data in our hybrid model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the images and tidy data in the same dataframe, split attributes and objective value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Bad\n",
      "1         Bad\n",
      "2         Bad\n",
      "3         Bad\n",
      "4         Bad\n",
      "         ... \n",
      "10454    Good\n",
      "10455     Bad\n",
      "10456     Bad\n",
      "10457     Bad\n",
      "10458     Bad\n",
      "Name: class, Length: 10459, dtype: object\n"
     ]
    }
   ],
   "source": [
    "combined_dataset = pd.concat([imgs,df_normalized[columns_to_normalize]],axis=1)\n",
    "\n",
    "df_x = combined_dataset.drop(\"class\",axis=1)\n",
    "df_y = combined_dataset[\"class\"]\n",
    "\n",
    "print(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section36\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.6. Label encoding</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this section, we delve into label encoding, a crucial preprocessing step for preparing categorical labels for use in machine learning models. Specifically for binary classification tasks, label encoding involves transforming categorical labels into a binary format, represented by the integers 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df_y = encoder.fit_transform(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF1lJWbojpD3"
   },
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 4. Pre-modelling phase</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is ready, we load it into memory with an iterator in order to pass it to the ViT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section41\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 4.1. Data curation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each method generates images of **different pixel size**. For example:\n",
    "- `TINTO` method has a parameter that you can specify the size in pixels which by default is 20. \n",
    "- Other parameters such as `Combined` generates the size automatically and you must obtain them from the _shape_ of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib documentation in [PyPI](https://tintolib.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in train/test/validation. \n",
    "\n",
    "Note that the partitioning of the images is also performed, in addition to the tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape:  (20, 20, 3)\n",
      "Attributres:  23\n",
      "Image size (pixels): 20\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size = 0.40, random_state = 123)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.50, random_state = 123)\n",
    "\n",
    "#TIDY DATA SPLITTED\n",
    "X_train_num = X_train.drop(\"images\",axis=1)\n",
    "X_val_num = X_val.drop(\"images\",axis=1)\n",
    "X_test_num = X_test.drop(\"images\",axis=1)\n",
    "\n",
    "#IMAGES\n",
    "# For 3 canal (RGB)\n",
    "X_train_img = np.array([cv2.resize(cv2.imread(img),(pixels,pixels)) for img in X_train[\"images\"]])\n",
    "X_val_img = np.array([cv2.resize(cv2.imread(img),(pixels,pixels)) for img in X_val[\"images\"]])\n",
    "X_test_img = np.array([cv2.resize(cv2.imread(img),(pixels,pixels)) for img in X_test[\"images\"]])\n",
    "\n",
    "# For 1 canal (GRAY SCALE)\n",
    "\"\"\"X_train_img = np.array([cv2.imread(img,cv2.IMREAD_GRAYSCALE) for img in X_train[\"images\"]])\n",
    "X_val_img = np.array([cv2.imread(img,cv2.IMREAD_GRAYSCALE) for img in X_val[\"images\"]])\n",
    "X_test_img = np.array([cv2.imread(img,cv2.IMREAD_GRAYSCALE) for img in X_test[\"images\"]])\"\"\"\n",
    "\n",
    "# Convert the Numpy arrays to TensorFlow tensors and normalize the pixel values to [0, 1]\n",
    "X_train_img = tf.convert_to_tensor(X_train_img, dtype=tf.float32) / 255.0\n",
    "X_val_img = tf.convert_to_tensor(X_val_img, dtype=tf.float32) / 255.0\n",
    "X_test_img = tf.convert_to_tensor(X_test_img, dtype=tf.float32) / 255.0\n",
    "\n",
    "attributes = len(X_train_num.columns)\n",
    "input_shape = X_train_img[0].shape\n",
    "\n",
    "print(\"Images shape: \",input_shape)\n",
    "print(\"Attributres: \",attributes)\n",
    "pixels=X_train_img[0].shape[0]\n",
    "print(\"Image size (pixels):\", pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 5. Modeling hybrid network</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start the ViT+MLP training. Before that we prepare the algorithm for reading data.\n",
    "\n",
    "In this example, 2 branch networks is created\n",
    "- 1º branch: FFNN for tabular data\n",
    "- 2º branch: ViT for TINTOlib images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section51\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.1. FFNN for tabular data</font>\n",
    "\n",
    "This is an example of a simple FFNN for tabular data. Note that we are not looking for the optimization of the ViT but to show an example of TINTOlib execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_ffnn = [64,32,16]\n",
    "\n",
    "ff_model = keras.Sequential()\n",
    "ff_model.add(keras.Input(shape=(attributes,)))\n",
    "\n",
    "for layer in filters_ffnn:\n",
    "    ff_model.add(layers.Dense(layer, activation=\"gelu\"))\n",
    "    ff_model.add(Dropout(dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 16), dtype=float32, sparse=False, name=keras_tensor_362>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_model(keras.Input(shape=(attributes,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section52\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.2. ViT for TINTOlib images</font>\n",
    "\n",
    "This is an example of a simple ViT for TINTOlib images. Note that we are not looking for the optimization of the ViT but to show an example of TINTOlib execution.\n",
    "\n",
    "It is crucial to select an appropriate patch size. The patch size should be a divisor of the input image size; for example, an image of 20x20 with a patch size of 5 would result in a total of 16 patches (4x4 grid). Given the high computational cost, the patch size should be carefully chosen based on the dimensions of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código define los hiperparámetros para el modelo ViT implementado en TensorFlow y Keras. Los hiperparámetros son los siguientes:\n",
    "\n",
    "* `learning_rate`: tasa de aprendizaje para el optimizador.\n",
    "* `weight_decay`: valor de decaimiento de peso para regularización L2.\n",
    "* `batch_size`: tamaño del lote de entrenamiento.\n",
    "* `num_epochs`: número de épocas de entrenamiento.\n",
    "* `image_size`: tamaño de las imágenes de entrada.\n",
    "* `patch_size`: tamaño de los parches extraídos de las imágenes.\n",
    "* `num_patches`: número total de parches extraídos de cada imagen.\n",
    "* `projection_dim`: dimensión de la proyección lineal para los parches.\n",
    "* `num_heads`: número de cabezas de atención en el transformador.\n",
    "* `transformer_units`: lista de unidades en las capas del transformador.\n",
    "* `transformer_layers`: número de capas en el transformador.\n",
    "* `mlp_head_units`: lista de unidades en las capas densas del clasificador final.\n",
    "\n",
    "Estos hiperparámetros se utilizan para configurar el modelo ViT y su proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 10  # For real training, use num_epochs=100. 10 is a test value\n",
    "image_size = 20  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [\n",
    "    1024,\n",
    "    512,\n",
    "    16\n",
    "]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        input_shape = ops.shape(images)\n",
    "        batch_size = input_shape[0]\n",
    "        height = input_shape[1]\n",
    "        width = input_shape[2]\n",
    "        channels = input_shape[3]\n",
    "        num_patches_h = height // self.patch_size\n",
    "        num_patches_w = width // self.patch_size\n",
    "        patches = keras.ops.image.extract_patches(images, size=self.patch_size)\n",
    "        patches = ops.reshape(\n",
    "            patches,\n",
    "            (\n",
    "                batch_size,\n",
    "                num_patches_h * num_patches_w,\n",
    "                self.patch_size * self.patch_size * channels,\n",
    "            ),\n",
    "        )\n",
    "        return patches\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = ops.expand_dims(\n",
    "            ops.arange(start=0, stop=self.num_patches, step=1), axis=0\n",
    "        )\n",
    "        projected_patches = self.projection(patch)\n",
    "        encoded = projected_patches + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_patches\": self.num_patches})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=keras.activations.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    print(inputs.shape)\n",
    "\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=features)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 20, 20, 3)\n"
     ]
    }
   ],
   "source": [
    "vit_model = create_vit_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section53\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.3. Concatenate branches</font>\n",
    "\n",
    "Finally, we must concatenate the output of the CNN branch with the output of the FFNN branch in a final FFNN that will give the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the outputs\n",
    "combined_output = layers.concatenate([ff_model.output, vit_model.output])\n",
    "x = Dense(32, activation=\"relu\")(combined_output)\n",
    "x = Dense(16, activation=\"relu\")(combined_output)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=[ff_model.input, vit_model.input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 16), dtype=float32, sparse=False, name=keras_tensor_362>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 16), dtype=float32, sparse=False, name=keras_tensor_447>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section54\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.4. Metrics</font>\n",
    "\n",
    "Define metrics and some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    #tf.keras.metrics.TruePositives(name = 'tp'),\n",
    "    #tf.keras.metrics.FalsePositives(name = 'fp'),\n",
    "    #tf.keras.metrics.TrueNegatives(name = 'tn'),\n",
    "    #tf.keras.metrics.FalseNegatives(name = 'fn'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name ='accuracy'),\n",
    "    tf.keras.metrics.Precision(name = 'precision'),\n",
    "    tf.keras.metrics.Recall(name = 'recall'),\n",
    "    tf.keras.metrics.AUC(name = 'auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_39\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_39\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ patches_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Patches</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ patch_encoder_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,552</span> │ patches_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PatchEncoder</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ patch_encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │                   │            │ patch_encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_97          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_97[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_98          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ add_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │                   │            │ add_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_100         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_100[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_101         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_101[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ add_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │                   │            │ add_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_103         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_103[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_104         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_104[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ add_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │                   │            │ add_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_106         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_106[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_107         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_107[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ add_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │                   │            │ add_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_109         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_90[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_109[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_110         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_91[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_110[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ add_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │                   │            │ add_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_112         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_92[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_112[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_113         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_113[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ add_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │                   │            │ add_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_115         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_115[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_116         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_95[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_116[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ add_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │                   │            │ add_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_118         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_96[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_118[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_119         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_97[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_119[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ add_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_120         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,848</span> │ dropout_120[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_121         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dropout_121[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_122         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,208</span> │ dropout_122[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,144</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_123         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_100[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_123[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dense_102[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ patches_3 (\u001b[38;5;33mPatches\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m108\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ patch_encoder_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m7,552\u001b[0m │ patches_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mPatchEncoder\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ patch_encoder_3[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_48 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │                   │            │ patch_encoder_3[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_82 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_97          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_83 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m8,256\u001b[0m │ dropout_97[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_98          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_49 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ add_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_50 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │                   │            │ add_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_100         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_85 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m8,256\u001b[0m │ dropout_100[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_101         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_51 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_101[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ add_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_52 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │                   │            │ add_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_86 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_103         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_87 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m8,256\u001b[0m │ dropout_103[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_104         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_53 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_104[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ add_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_54 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │                   │            │ add_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_88 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_106         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_88[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_89 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m8,256\u001b[0m │ dropout_106[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_107         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_89[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_55 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_107[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ add_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_56 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │                   │            │ add_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_90 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_109         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_90[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_91 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m8,256\u001b[0m │ dropout_109[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_110         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_91[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_57 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_110[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ add_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_58 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │                   │            │ add_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_92 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_112         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_92[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_93 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m8,256\u001b[0m │ dropout_112[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_113         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_59 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_113[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ add_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_60 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │                   │            │ add_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_94 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_115         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_95 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m8,256\u001b[0m │ dropout_115[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_116         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_95[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_61 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_116[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ add_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_62 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │                   │            │ add_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_96 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_118         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_96[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m8,256\u001b[0m │ dropout_118[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_119         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_97[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_63 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_119[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ add_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_120         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │    \u001b[38;5;34m590,848\u001b[0m │ dropout_120[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_121         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m524,800\u001b[0m │ dropout_121[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_122         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m8,208\u001b[0m │ dropout_122[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m4,144\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_123         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_100[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ sequential_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_123[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_102 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_103 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dense_102[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,801,825</span> (6.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,801,825\u001b[0m (6.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,801,825</span> (6.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,801,825\u001b[0m (6.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "model.summary()\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "# Redirect the summary output to the specified file\n",
    "with open(results_folder+\"/model_summary.txt\", \"w\") as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "# Now, you can also save the model plot\n",
    "plot_model(model, to_file='model_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section55\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.5. Compile and fit</font>\n",
    "\n",
    "Note to specify the **loss depending** on whether you have a binary or multiclass classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS\n",
    "opt = Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=opt,\n",
    "    metrics = METRICS\n",
    ")\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6275,)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure EarlyStopping for binary classification\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor the validation accuracy\n",
    "    min_delta=0.001,         # Minimum change in the monitored quantity to qualify as an improvement\n",
    "    patience=10,             # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,               # Log when training stops\n",
    "    mode='max',              # Maximize the accuracy;\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 34ms/step - accuracy: 0.5774 - auc: 0.6070 - loss: 0.7005 - precision: 0.5707 - recall: 0.5028 - val_accuracy: 0.7032 - val_auc: 0.7610 - val_loss: 0.5845 - val_precision: 0.7187 - val_recall: 0.6103\n",
      "Epoch 2/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 34ms/step - accuracy: 0.6885 - auc: 0.7581 - loss: 0.5865 - precision: 0.6877 - recall: 0.6460 - val_accuracy: 0.7141 - val_auc: 0.7718 - val_loss: 0.5726 - val_precision: 0.7143 - val_recall: 0.6579\n",
      "Epoch 3/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 36ms/step - accuracy: 0.7050 - auc: 0.7690 - loss: 0.5749 - precision: 0.7111 - recall: 0.6513 - val_accuracy: 0.7180 - val_auc: 0.7783 - val_loss: 0.5671 - val_precision: 0.7303 - val_recall: 0.6387\n",
      "Epoch 4/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.7107 - auc: 0.7777 - loss: 0.5673 - precision: 0.7188 - recall: 0.6545 - val_accuracy: 0.7223 - val_auc: 0.7822 - val_loss: 0.5652 - val_precision: 0.7259 - val_recall: 0.6619\n",
      "Epoch 5/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.7135 - auc: 0.7813 - loss: 0.5642 - precision: 0.7265 - recall: 0.6481 - val_accuracy: 0.7237 - val_auc: 0.7841 - val_loss: 0.5623 - val_precision: 0.7400 - val_recall: 0.6397\n",
      "Epoch 6/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.7120 - auc: 0.7833 - loss: 0.5625 - precision: 0.7219 - recall: 0.6526 - val_accuracy: 0.7256 - val_auc: 0.7864 - val_loss: 0.5603 - val_precision: 0.7275 - val_recall: 0.6700\n",
      "Epoch 7/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.7169 - auc: 0.7883 - loss: 0.5566 - precision: 0.7253 - recall: 0.6624 - val_accuracy: 0.7290 - val_auc: 0.7874 - val_loss: 0.5593 - val_precision: 0.7291 - val_recall: 0.6781\n",
      "Epoch 8/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.7159 - auc: 0.7874 - loss: 0.5573 - precision: 0.7237 - recall: 0.6622 - val_accuracy: 0.7271 - val_auc: 0.7877 - val_loss: 0.5589 - val_precision: 0.7433 - val_recall: 0.6447\n",
      "Epoch 9/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.7217 - auc: 0.7912 - loss: 0.5541 - precision: 0.7285 - recall: 0.6716 - val_accuracy: 0.7290 - val_auc: 0.7890 - val_loss: 0.5579 - val_precision: 0.7316 - val_recall: 0.6731\n",
      "Epoch 10/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.7192 - auc: 0.7930 - loss: 0.5518 - precision: 0.7292 - recall: 0.6621 - val_accuracy: 0.7299 - val_auc: 0.7879 - val_loss: 0.5585 - val_precision: 0.7368 - val_recall: 0.6660\n",
      "Epoch 11/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.7243 - auc: 0.7942 - loss: 0.5507 - precision: 0.7335 - recall: 0.6701 - val_accuracy: 0.7280 - val_auc: 0.7878 - val_loss: 0.5575 - val_precision: 0.7367 - val_recall: 0.6599\n",
      "Epoch 12/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.7262 - auc: 0.7943 - loss: 0.5505 - precision: 0.7367 - recall: 0.6701 - val_accuracy: 0.7280 - val_auc: 0.7891 - val_loss: 0.5577 - val_precision: 0.7290 - val_recall: 0.6751\n",
      "Epoch 13/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 31ms/step - accuracy: 0.7260 - auc: 0.7946 - loss: 0.5499 - precision: 0.7403 - recall: 0.6626 - val_accuracy: 0.7314 - val_auc: 0.7907 - val_loss: 0.5580 - val_precision: 0.7290 - val_recall: 0.6862\n",
      "Epoch 14/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.7232 - auc: 0.7939 - loss: 0.5502 - precision: 0.7360 - recall: 0.6621 - val_accuracy: 0.7290 - val_auc: 0.7898 - val_loss: 0.5585 - val_precision: 0.7281 - val_recall: 0.6802\n",
      "Epoch 15/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.7238 - auc: 0.7939 - loss: 0.5509 - precision: 0.7332 - recall: 0.6686 - val_accuracy: 0.7299 - val_auc: 0.7893 - val_loss: 0.5569 - val_precision: 0.7353 - val_recall: 0.6690\n",
      "Epoch 16/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.7280 - auc: 0.7978 - loss: 0.5465 - precision: 0.7396 - recall: 0.6702 - val_accuracy: 0.7294 - val_auc: 0.7899 - val_loss: 0.5577 - val_precision: 0.7259 - val_recall: 0.6862\n",
      "Epoch 17/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7245 - auc: 0.7957 - loss: 0.5485 - precision: 0.7348 - recall: 0.6679 - val_accuracy: 0.7309 - val_auc: 0.7904 - val_loss: 0.5592 - val_precision: 0.7162 - val_recall: 0.7126\n",
      "Epoch 18/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.7222 - auc: 0.7964 - loss: 0.5484 - precision: 0.7319 - recall: 0.6660 - val_accuracy: 0.7318 - val_auc: 0.7905 - val_loss: 0.5562 - val_precision: 0.7349 - val_recall: 0.6761\n",
      "Epoch 19/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.7243 - auc: 0.7949 - loss: 0.5504 - precision: 0.7404 - recall: 0.6571 - val_accuracy: 0.7280 - val_auc: 0.7907 - val_loss: 0.5573 - val_precision: 0.7189 - val_recall: 0.6964\n",
      "Epoch 20/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.7227 - auc: 0.7945 - loss: 0.5494 - precision: 0.7320 - recall: 0.6674 - val_accuracy: 0.7304 - val_auc: 0.7903 - val_loss: 0.5579 - val_precision: 0.7168 - val_recall: 0.7095\n",
      "Epoch 21/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 31ms/step - accuracy: 0.7227 - auc: 0.7971 - loss: 0.5493 - precision: 0.7371 - recall: 0.6580 - val_accuracy: 0.7337 - val_auc: 0.7896 - val_loss: 0.5554 - val_precision: 0.7452 - val_recall: 0.6630\n",
      "Epoch 22/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.7287 - auc: 0.8001 - loss: 0.5435 - precision: 0.7413 - recall: 0.6698 - val_accuracy: 0.7285 - val_auc: 0.7892 - val_loss: 0.5562 - val_precision: 0.7349 - val_recall: 0.6650\n",
      "Epoch 23/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.7235 - auc: 0.7970 - loss: 0.5473 - precision: 0.7319 - recall: 0.6705 - val_accuracy: 0.7309 - val_auc: 0.7907 - val_loss: 0.5562 - val_precision: 0.7258 - val_recall: 0.6913\n",
      "Epoch 24/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.7288 - auc: 0.7987 - loss: 0.5456 - precision: 0.7370 - recall: 0.6775 - val_accuracy: 0.7328 - val_auc: 0.7913 - val_loss: 0.5570 - val_precision: 0.7200 - val_recall: 0.7105\n",
      "Epoch 25/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.7284 - auc: 0.7989 - loss: 0.5454 - precision: 0.7341 - recall: 0.6818 - val_accuracy: 0.7256 - val_auc: 0.7910 - val_loss: 0.5607 - val_precision: 0.6975 - val_recall: 0.7399\n",
      "Epoch 26/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.7279 - auc: 0.7999 - loss: 0.5431 - precision: 0.7365 - recall: 0.6758 - val_accuracy: 0.7314 - val_auc: 0.7899 - val_loss: 0.5555 - val_precision: 0.7252 - val_recall: 0.6943\n",
      "Epoch 27/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.7317 - auc: 0.7993 - loss: 0.5454 - precision: 0.7407 - recall: 0.6795 - val_accuracy: 0.7299 - val_auc: 0.7899 - val_loss: 0.5556 - val_precision: 0.7243 - val_recall: 0.6913\n",
      "Epoch 28/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.7270 - auc: 0.7982 - loss: 0.5446 - precision: 0.7388 - recall: 0.6684 - val_accuracy: 0.7323 - val_auc: 0.7906 - val_loss: 0.5560 - val_precision: 0.7238 - val_recall: 0.7004\n",
      "Epoch 29/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.7231 - auc: 0.7997 - loss: 0.5428 - precision: 0.7324 - recall: 0.6683 - val_accuracy: 0.7280 - val_auc: 0.7887 - val_loss: 0.5551 - val_precision: 0.7270 - val_recall: 0.6791\n",
      "Epoch 30/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.7254 - auc: 0.8002 - loss: 0.5441 - precision: 0.7321 - recall: 0.6767 - val_accuracy: 0.7314 - val_auc: 0.7902 - val_loss: 0.5565 - val_precision: 0.7178 - val_recall: 0.7105\n",
      "Epoch 31/50\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.7256 - auc: 0.7993 - loss: 0.5438 - precision: 0.7273 - recall: 0.6863 - val_accuracy: 0.7314 - val_auc: 0.7900 - val_loss: 0.5547 - val_precision: 0.7330 - val_recall: 0.6781\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n"
     ]
    }
   ],
   "source": [
    "model_history=model.fit(\n",
    "    x=[X_train_num, X_train_img], y=y_train,\n",
    "    validation_data=([X_val_num, X_val_img], y_val),\n",
    "    epochs=epochs, \n",
    "    batch_size=8,\n",
    "    callbacks = [early_stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['accuracy', 'auc', 'loss', 'precision', 'recall', 'val_accuracy', 'val_auc', 'val_loss', 'val_precision', 'val_recall'])\n"
     ]
    }
   ],
   "source": [
    "print(model_history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section6\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 6. Results</font>\n",
    "\n",
    "Finally, we can evaluate our hybrid model with the images created by TINTOlib in any of the ways represented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section61\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 6.1. Train/Validation representation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(model_history.history['loss'])\n",
    "plt.plot(model_history.history['loss'], color = 'red', label = 'loss')\n",
    "plt.plot(model_history.history['val_loss'], color = 'green', label = 'val loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['accuracy'], color = 'red', label = 'accuracy')\n",
    "plt.plot(model_history.history['val_accuracy'], color = 'green', label = 'val accuracy')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section62\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 6.2. Validation/Test evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 7/66\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7843 - auc: 0.8374 - loss: 0.5109 - precision: 0.8152 - recall: 0.6865"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7323 - auc: 0.7990 - loss: 0.5465 - precision: 0.7603 - recall: 0.6514\n"
     ]
    }
   ],
   "source": [
    "score_test= model.evaluate([X_test_num, X_test_img], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([X_test_num,X_test_img],)\n",
    "real_values= y_test\n",
    "predicted_classes = np.argmax(prediction, axis = 1)\n",
    "\n",
    "result = [list(t) for t in zip(predicted_classes, real_values)]\n",
    "#print(np.round(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7194072604179382\n",
      "Test AUC: 0.7920225858688354\n",
      "Test precision: 0.7406989932060242\n",
      "Test recall: 0.6479290127754211\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = score_test[1]\n",
    "test_auc = score_test[4]\n",
    "test_precision = score_test[2]\n",
    "test_recall = score_test[3]\n",
    "\n",
    "print(\"Test accuracy:\",test_accuracy)\n",
    "print(\"Test AUC:\",test_auc)\n",
    "print(\"Test precision:\",test_precision)\n",
    "print(\"Test recall:\",test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: ./results_heloc_TINTO_1\\test_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Create a folder to save results\n",
    "import os\n",
    "folder_path = results_folder\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Save the results to a text file\n",
    "results_file_path = os.path.join(folder_path, \"test_results.txt\")\n",
    "with open(results_file_path, \"w\") as file:\n",
    "    file.write(\"Test accuracy: {}\\n\".format(test_accuracy))\n",
    "    file.write(\"Test AUC: {}\\n\".format(test_auc))\n",
    "    file.write(\"Test precision: {}\\n\".format(test_precision))\n",
    "    file.write(\"Test recall: {}\\n\".format(test_recall))\n",
    "\n",
    "print(\"Results saved to:\", results_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7190438508987427\n",
      "Train AUC: 0.7878432273864746\n",
      "Train precision: 0.7210884094238281\n",
      "Train recall: 0.6717811822891235\n",
      "Train loss: 0.5564674139022827\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = model_history.history[\"accuracy\"][-1]\n",
    "train_auc = model_history.history[\"auc\"][-1]\n",
    "train_precision = model_history.history[\"precision\"][-1]\n",
    "train_recall = model_history.history[\"recall\"][-1]\n",
    "train_loss = model_history.history[\"loss\"][-1]\n",
    "\n",
    "print(\"Train accuracy:\",train_accuracy)\n",
    "print(\"Train AUC:\",train_auc)\n",
    "print(\"Train precision:\",train_precision)\n",
    "print(\"Train recall:\",train_recall)\n",
    "print(\"Train loss:\",train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results saved to: ./results_heloc_TINTO_1\\train_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the train results to a text file\n",
    "train_results_file_path = os.path.join(folder_path, \"train_results.txt\")\n",
    "with open(train_results_file_path, \"w\") as file:\n",
    "    file.write(\"Train accuracy: {}\\n\".format(train_accuracy))\n",
    "    file.write(\"Train AUC: {}\\n\".format(train_auc))\n",
    "    file.write(\"Train precision: {}\\n\".format(train_precision))\n",
    "    file.write(\"Train recall: {}\\n\".format(train_recall))\n",
    "    file.write(\"Train loss: {}\\n\".format(train_loss))\n",
    "\n",
    "print(\"Train results saved to:\", train_results_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7313575744628906\n",
      "Validation AUC: 0.7899545431137085\n",
      "Validation precision: 0.7330415844917297\n",
      "Validation recall: 0.6781376600265503\n",
      "Validation loss: 0.5546963810920715\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy = model_history.history[\"val_accuracy\"][-1]\n",
    "validation_auc = model_history.history[\"val_auc\"][-1]\n",
    "validation_precision = model_history.history[\"val_precision\"][-1]\n",
    "validation_recall = model_history.history[\"val_recall\"][-1]\n",
    "validation_loss = model_history.history[\"val_loss\"][-1]\n",
    "\n",
    "print(\"Validation accuracy:\",validation_accuracy)\n",
    "print(\"Validation AUC:\",validation_auc)\n",
    "print(\"Validation precision:\",validation_precision)\n",
    "print(\"Validation recall:\",validation_recall)\n",
    "print(\"Validation loss:\",validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results saved to: ./results_heloc_TINTO_1\\validation_results.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the validation results to a text file\n",
    "validation_results_file_path = os.path.join(folder_path, \"validation_results.txt\")\n",
    "with open(validation_results_file_path, \"w\") as file:\n",
    "    file.write(\"Validation accuracy: {}\\n\".format(validation_accuracy))\n",
    "    file.write(\"Validation AUC: {}\\n\".format(validation_auc))\n",
    "    file.write(\"Validation precision: {}\\n\".format(validation_precision))\n",
    "    file.write(\"Validation recall: {}\\n\".format(validation_recall))\n",
    "    file.write(\"Validation loss: {}\\n\".format(validation_loss))\n",
    "\n",
    "print(\"Validation results saved to:\", validation_results_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1plFq1CpEXIdc9LankaLPiOObRg0_y5l2",
     "timestamp": 1684250343977
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
