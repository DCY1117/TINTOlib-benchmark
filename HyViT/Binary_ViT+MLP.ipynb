{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "#import openslide\n",
    "#from openslide.deepzoom import DeepZoomGenerator\n",
    "import tifffile as tifi\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,mean_absolute_percentage_error\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras import ops\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import vgg16, vgg19, resnet50, mobilenet, inception_resnet_v2, densenet, inception_v3, xception, nasnet, ResNet152V2\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, InputLayer, LayerNormalization\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.optimizers import SGD, Adam, Adadelta, Adamax\n",
    "from keras import layers, models, Model\n",
    "from keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from keras.layers import Input, Activation,MaxPooling2D, Concatenate, AveragePooling2D, Lambda\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Models of TINTOlib\n",
    "from TINTOlib.tinto import TINTO\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.combination import Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary ViT+MLP\n",
    "\n",
    "## Table of Contents\n",
    "1. [Dataset](#dataset)\n",
    "2. [Load and Preprocess](#load-and-preprocess)\n",
    "3. [Model Architectures](#model-architectures)\n",
    "4. [Metrics](#metrics)\n",
    "5. [Compile and Fit](#compile-and-fit)\n",
    "6. [Experiments](#experiments)\n",
    "    - [Experiment 1: TINTO](#experiment-1-tinto)\n",
    "    - [Experiment 2: IGTD](#experiment-2-igtd)\n",
    "    - [Experiment 3: REFINED](#experiment-3-refined)\n",
    "    - [Experiment 4: Bar Graph](#experiment-4-bar-graph)\n",
    "    - [Experiment 5: Distance Matrix](#experiment-5-distance-matrix)\n",
    "    - [Experiment 6: Combination](#experiment-6-combination)\n",
    "    - [Experiment 7: SuperTML](#experiment-7-supertml)\n",
    "7. [Final Metrics and Best Model](#final-metrics-and-best-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 64\n",
    "\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable to store dataset name\n",
    "dataset_name = 'preprocessed_heloc'\n",
    "results_path = f'logs/{dataset_name}/ViT+MLP_Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../Datasets_benchmark/Binary/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD AND PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the last column with LabelEncoder\n",
    "df.iloc[:, -1] = label_encoder.fit_transform(df.iloc[:, -1])\n",
    "\n",
    "# Display the updated last column\n",
    "print(df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_and_preprocess_data(images_folder, image_model, problem_type):\n",
    "\n",
    "    # Generate the images if the folder does not exist\n",
    "    if not os.path.exists(images_folder):\n",
    "        #Generate thet images\n",
    "        image_model.generateImages(df, images_folder)\n",
    "    else:\n",
    "        print(\"The images are already generated\")\n",
    "\n",
    "    img_paths = os.path.join(images_folder,problem_type+\".csv\")\n",
    "\n",
    "    print(img_paths)\n",
    "    \n",
    "    imgs = pd.read_csv(img_paths)\n",
    "\n",
    "    # Update image paths\n",
    "    imgs[\"images\"] = images_folder + \"/\" + imgs[\"images\"]\n",
    "\n",
    "    # Combine datasets\n",
    "    combined_dataset = pd.concat([imgs, df], axis=1)\n",
    "\n",
    "    # Split data\n",
    "    df_x = combined_dataset.drop(df.columns[-1], axis=1).drop(\"class\", axis=1)\n",
    "    df_y = combined_dataset[\"class\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size=0.20, random_state=SEED, stratify=df_y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.50, random_state=SEED, stratify=y_val)\n",
    "    # Numerical data\n",
    "    X_train_num = X_train.drop(\"images\", axis=1)\n",
    "    X_val_num = X_val.drop(\"images\", axis=1)\n",
    "    X_test_num = X_test.drop(\"images\", axis=1)\n",
    "\n",
    "    # Image data\n",
    "    X_train_img = np.array([cv2.imread(img) for img in X_train[\"images\"]])\n",
    "    X_val_img = np.array([cv2.imread(img) for img in X_val[\"images\"]])\n",
    "    X_test_img = np.array([cv2.imread(img) for img in X_test[\"images\"]])\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Scale numerical data\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "    X_val_num = pd.DataFrame(scaler.transform(X_val_num), columns=X_val_num.columns)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(X_test_num), columns=X_test_num.columns)\n",
    "\n",
    "    attributes = len(X_train_num.columns)\n",
    "    imgs_shape = X_train_img[0].shape\n",
    "\n",
    "    print(\"Images shape: \",imgs_shape)\n",
    "    print(\"Attributres: \",attributes)\n",
    "    pixels=X_train_img[0].shape[0]\n",
    "    print(\"Image size (pixels):\", pixels)\n",
    "\n",
    "    return X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL ARCHITECTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        input_shape = ops.shape(images)\n",
    "        batch_size = input_shape[0]\n",
    "        height = input_shape[1]\n",
    "        width = input_shape[2]\n",
    "        channels = input_shape[3]\n",
    "        num_patches_h = height // self.patch_size\n",
    "        num_patches_w = width // self.patch_size\n",
    "        patches = keras.ops.image.extract_patches(images, size=(self.patch_size,self.patch_size))\n",
    "        patches = ops.reshape(\n",
    "            patches,\n",
    "            (\n",
    "                batch_size,\n",
    "                num_patches_h * num_patches_w,\n",
    "                self.patch_size * self.patch_size * channels,\n",
    "            ),\n",
    "        )\n",
    "        return patches\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config\n",
    "    \n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim, emb_dropout):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches + 1, output_dim=projection_dim\n",
    "        )\n",
    "        self.cls_token = self.add_weight(\n",
    "            name=\"cls_token\",\n",
    "            shape=(1, 1, projection_dim),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True\n",
    "        )\n",
    "        self.dropout = layers.Dropout(rate=emb_dropout)\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = ops.expand_dims(\n",
    "            ops.arange(start=0, stop=self.num_patches + 1, step=1), axis=0\n",
    "        )\n",
    "        projected_patches = self.projection(patch)\n",
    "\n",
    "        # Get the batch size from the input feature shape\n",
    "        batch_size = tf.shape(patch)[0]\n",
    "\n",
    "        # Repeat the CLS token for each item in the batch\n",
    "        cls_tokens = tf.repeat(self.cls_token, batch_size, axis=0)\n",
    "\n",
    "        # Concatenate CLS token with projected patches\n",
    "        encoded = tf.concat([cls_tokens, projected_patches], axis=1)\n",
    "\n",
    "        encoded = encoded + self.position_embedding(positions)\n",
    "\n",
    "        encoded = self.dropout(encoded)\n",
    "\n",
    "        return encoded\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_patches\": self.num_patches})\n",
    "        return config\n",
    "    \n",
    "class FeedForward(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = tf.keras.Sequential([tf.keras.layers.Dense(hidden_dim, activation=keras.activations.gelu),\n",
    "                                        tf.keras.layers.Dense(dim)])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class ViT(keras.Model):\n",
    "    def __init__(self, image_size, patch_size, dim, depth, heads, mlp_dim,\n",
    "                pool='cls', dim_head=64, dropout=0.0, emb_dropout=0.0):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        self.dim = dim\n",
    "        self.depth = depth\n",
    "        self.heads = heads\n",
    "        self.mlp_dim = mlp_dim\n",
    "        self.pool = pool\n",
    "        self.dim_head = dim_head\n",
    "        self.dropout = dropout\n",
    "        self.emb_dropout = emb_dropout\n",
    "        \n",
    "        assert image_size % patch_size == 0, 'image dimensions must be divisible by the patch size'\n",
    "        self.num_patches = (image_size // patch_size) ** 2\n",
    "        \n",
    "        self.patch_layer = Patches(patch_size)\n",
    "        \n",
    "        self.patch_encoder = PatchEncoder(self.num_patches, dim, emb_dropout)\n",
    "        \n",
    "        self.transformer_blocks = [self.create_transformer_block() for _ in range(depth)]\n",
    "        \n",
    "        self.layer_norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "\n",
    "    def create_transformer_block(self):\n",
    "        return {\n",
    "            'layer_norm1': layers.LayerNormalization(epsilon=1e-6),\n",
    "            'attention': layers.MultiHeadAttention(num_heads=self.heads, key_dim=self.dim_head, dropout=self.dropout),\n",
    "            'layer_norm2': layers.LayerNormalization(epsilon=1e-6),\n",
    "            'mlp': FeedForward(self.dim, self.mlp_dim)\n",
    "        }\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.patch_layer(inputs)\n",
    "        x = self.patch_encoder(x)\n",
    "        \n",
    "        # Compute multiple layers of the Transformer block.\n",
    "        for block in self.transformer_blocks:\n",
    "            # Layer normalization 1.\n",
    "            x1 = block['layer_norm1'](x)\n",
    "            # Create a multi-head attention layer.\n",
    "            attention_output = block['attention'](x1, x1)\n",
    "            # Skip connection 1.\n",
    "            x2 = layers.Add()([attention_output, x])\n",
    "            # Layer normalization 2.\n",
    "            x3 = block['layer_norm2'](x2)\n",
    "            # MLP.\n",
    "            x3 = block['mlp'](x3)\n",
    "            # Skip connection 2.\n",
    "            x = layers.Add()([x3, x2])\n",
    "        \n",
    "        representation = self.layer_norm(x)\n",
    "        \n",
    "        if self.pool == 'mean':\n",
    "            return tf.reduce_mean(representation, axis=1)\n",
    "        else:\n",
    "            return representation[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT + MLP\n",
    "\n",
    "def create_model1(attributes, imgs_shape):\n",
    "    # ViT branch\n",
    "    vit_input = Input(shape=imgs_shape)\n",
    "\n",
    "    vit_model = ViT(\n",
    "        image_size = imgs_shape[0],\n",
    "        patch_size = imgs_shape[0],\n",
    "        dim = 64,\n",
    "        depth = 2,\n",
    "        heads = 4,\n",
    "        mlp_dim = 128,\n",
    "        dropout = 0.1,\n",
    "        emb_dropout = 0.1\n",
    "    )\n",
    "\n",
    "    vit_output = vit_model(vit_input)\n",
    "\n",
    "    vit_output = Dense(32, activation='relu')(vit_output)\n",
    "    vit_output = Dense(16, activation='relu')(vit_output)\n",
    "\n",
    "    # MLP branch\n",
    "    mlp_input = Input(shape=(attributes,))\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_input)\n",
    "    mlp_output = Dense(32, activation='relu')(mlp_output)\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_output)\n",
    "\n",
    "    # Concatenate the outputs of CNN and MLP branches\n",
    "    concat_output = Concatenate()([vit_output, mlp_output])\n",
    "\n",
    "    # Final MLP\n",
    "    final_output = Dense(32, activation='relu')(concat_output)\n",
    "    final_output = Dense(16, activation='relu')(final_output)\n",
    "    final_output = Dense(8, activation='relu')(final_output)\n",
    "    final_output = Dense(1, activation='sigmoid')(final_output)  # Output layer for regression\n",
    "\n",
    "    # Create the hybrid model\n",
    "    model1 = Model(inputs=[mlp_input, vit_input], outputs=final_output)\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT with patch size as divisor of image size\n",
    "# ViT + MLP\n",
    "\n",
    "def find_divisors(n):\n",
    "    divisors = []\n",
    "    for i in range(1, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            divisors.append(i)\n",
    "            if i != n // i:  # Check to include both divisors if they are not the same\n",
    "                divisors.append(n // i)\n",
    "    divisors.sort()\n",
    "    return divisors\n",
    "\n",
    "def create_model2(attributes, imgs_shape):\n",
    "    divisors = find_divisors(imgs_shape[0])\n",
    "    \n",
    "    vit_input = Input(shape=imgs_shape)\n",
    "\n",
    "    vit_model = ViT(\n",
    "        image_size = imgs_shape[0],\n",
    "        patch_size = divisors[-2],\n",
    "        dim = 64,\n",
    "        depth = 2,\n",
    "        heads = 4,\n",
    "        mlp_dim = 128,\n",
    "        dropout = 0.1,\n",
    "        emb_dropout = 0.1\n",
    "    )\n",
    "\n",
    "    vit_output = vit_model(vit_input)\n",
    "\n",
    "    vit_output = Dense(64, activation='relu')(vit_output)\n",
    "    vit_output = Dense(32, activation='relu')(vit_output)\n",
    "    vit_output = Dense(16, activation='relu')(vit_output)\n",
    "\n",
    "    # MLP branch\n",
    "    mlp_input = Input(shape=(attributes,))\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_input)\n",
    "    mlp_output = Dense(32, activation='relu')(mlp_output)\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_output)\n",
    "\n",
    "    # Concatenate the outputs of CNN and MLP branches\n",
    "    concat_output = Concatenate()([vit_output, mlp_output])\n",
    "\n",
    "    # Final MLP\n",
    "    final_output = Dense(32, activation='relu')(concat_output)\n",
    "    final_output = Dense(16, activation='relu')(final_output)\n",
    "    final_output = Dense(8, activation='relu')(final_output)\n",
    "    final_output = Dense(1, activation='sigmoid')(final_output)  # Output layer for regression\n",
    "\n",
    "    # Create the hybrid model\n",
    "    model2 = Model(inputs=[mlp_input, vit_input], outputs=final_output)\n",
    "\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model3(imgs_shape, attributes):\n",
    "    divisors = find_divisors(imgs_shape[0])\n",
    "    \n",
    "    vit_input = Input(shape=imgs_shape)\n",
    "\n",
    "    vit_model = ViT(\n",
    "        image_size = imgs_shape[0],\n",
    "        patch_size = divisors[-3],\n",
    "        dim = 64,\n",
    "        depth = 2,\n",
    "        heads = 4,\n",
    "        mlp_dim = 128,\n",
    "        dropout = 0.1,\n",
    "        emb_dropout = 0.1\n",
    "    )\n",
    "\n",
    "    vit_output = vit_model(vit_input)\n",
    "\n",
    "    vit_output = Dense(64, activation='relu')(vit_output)\n",
    "    vit_output = Dense(32, activation='relu')(vit_output)\n",
    "    vit_output = Dense(16, activation='relu')(vit_output)\n",
    "\n",
    "    # MLP branch\n",
    "    mlp_input = Input(shape=(attributes,))\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_input)\n",
    "    mlp_output = Dense(32, activation='relu')(mlp_output)\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_output)\n",
    "\n",
    "    # Concatenate the outputs of CNN and MLP branches\n",
    "    concat_output = Concatenate()([vit_output, mlp_output])\n",
    "\n",
    "    # Final MLP\n",
    "    final_output = Dense(32, activation='relu')(concat_output)\n",
    "    final_output = Dense(16, activation='relu')(final_output)\n",
    "    final_output = Dense(8, activation='relu')(final_output)\n",
    "    final_output = Dense(1, activation='sigmoid')(final_output)  # Output layer for regression\n",
    "\n",
    "    # Create the hybrid model\n",
    "    model3 = Model(inputs=[mlp_input, vit_input], outputs=final_output)\n",
    "\n",
    "    return model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    #tf.keras.metrics.TruePositives(name = 'tp'),\n",
    "    #tf.keras.metrics.FalsePositives(name = 'fp'),\n",
    "    #tf.keras.metrics.TrueNegatives(name = 'tn'),\n",
    "    #tf.keras.metrics.FalseNegatives(name = 'fn'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name ='accuracy'),\n",
    "    tf.keras.metrics.Precision(name = 'precision'),\n",
    "    tf.keras.metrics.Recall(name = 'recall'),\n",
    "    tf.keras.metrics.AUC(name = 'auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPILE AND FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, model_name, batch_size=32, epochs=200, lr=1e-3):\n",
    "\n",
    "    opt = Adam(learning_rate=lr)\n",
    "\n",
    "    # Define the early stopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',  # Monitor the validation loss\n",
    "        min_delta=0.001,     # Minimum change in the monitored quantity to qualify as an improvement\n",
    "        patience=20,          # Number of epochs with no improvement after which training will be stopped\n",
    "        verbose=1,           # Print messages when the callback takes an action\n",
    "        mode='min',           # Training will stop when the quantity monitored has stopped decreasing\n",
    "        restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "    )\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=opt,\n",
    "        metrics=METRICS\n",
    "    )\n",
    "\n",
    "    model_history = model.fit(\n",
    "        x=[X_train_num,X_train_img], y=y_train,\n",
    "        validation_data=([X_val_num,X_val_img], y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    os.makedirs(f\"models/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['loss'], color = 'red', label = 'loss')\n",
    "    plt.plot(model_history.history['val_loss'], color = 'green', label = 'val loss')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/loss_plot.png\")\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['accuracy'], color = 'red', label = 'accuracy')\n",
    "    plt.plot(model_history.history['val_accuracy'], color = 'green', label = 'val accuracy')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/accuracy_plot.png\")\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['auc'], color = 'red', label = 'auc')\n",
    "    plt.plot(model_history.history['val_auc'], color = 'green', label = 'val auc')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/auc_plot.png\")\n",
    "\n",
    "    # Save the model\n",
    "    os.makedirs(f\"models/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "    model.save(f\"models/{dataset_name}/{model_name}/model_{dataset_name}.keras\")\n",
    "\n",
    "    # Evaluate the model on the training set\n",
    "    train_scores = model.evaluate([X_train_num,X_train_img], y_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_scores = model.evaluate([X_val_num,X_val_img], y_val)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    score_test = model.evaluate([X_test_num,X_test_img], y_test)\n",
    "\n",
    "    # Save training, validation, and test scores\n",
    "    metrics = {\n",
    "        'train_loss': train_scores[0],\n",
    "        'train_accuracy': train_scores[1],\n",
    "        'train_precision': train_scores[2],\n",
    "        'train_recall': train_scores[3],\n",
    "        'train_auc': train_scores[4],\n",
    "        'val_loss': val_scores[0],\n",
    "        'val_accuracy': val_scores[1],\n",
    "        'val_precision': val_scores[2],\n",
    "        'val_recall': val_scores[3],\n",
    "        'val_auc': val_scores[4],\n",
    "        'test_loss': score_test[0],\n",
    "        'test_accuracy': score_test[1],\n",
    "        'test_precision': score_test[2],\n",
    "        'test_recall': score_test[3],\n",
    "        'test_auc': score_test[4]\n",
    "    }\n",
    "\n",
    "    # Save metrics to a file\n",
    "    os.makedirs(f'{results_path}/{model_name}', exist_ok=True)\n",
    "    with open(f'{results_path}/{model_name}/{dataset_name}_metrics.txt', 'w') as f:\n",
    "        for key, value in metrics.items():\n",
    "            f.write(f'{key}: {value}\\n')\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test,dataset_name, model_name, batch_size=32, epochs=200, lr=1e-3):\n",
    "    try:\n",
    "        if model is None:\n",
    "            print(f\"Model {model_name} is None\")\n",
    "            return None\n",
    "        else:\n",
    "            metrics = compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test,dataset_name, model_name, batch_size, epochs, lr)\n",
    "            return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to compile and fit {model_name}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_create_model(create_model_func, attributes, imgs_shape):\n",
    "    try:\n",
    "        model = create_model_func(attributes, imgs_shape)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, blur=True, random_seed=SEED)\n",
    "#image_model = REFINED(problem= problem_type,hcIterations=5)\n",
    "#image_model = IGTD(problem= problem_type)\n",
    "#image_model = BarGraph(problem= problem_type)\n",
    "#image_model = DistanceMatrix(problem= problem_type)\n",
    "#image_model = Combination(problem= problem_type)\n",
    "#image_model = SuperTML(problem= problem_type)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_IGTD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default the seed is 1 for all experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 1: TINTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, blur=True, random_seed=SEED)\n",
    "name = f\"TINTO_blur\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, blur=True, option=\"maximum\", random_seed=SEED)\n",
    "name = f\"TINTO_blur_maximum\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, random_seed=SEED)\n",
    "name = f\"TINTO\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 2: IGTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the dataframe\n",
    "num_columns = df.shape[1]\n",
    "\n",
    "# Calculate number of columns - 1\n",
    "columns_minus_one = num_columns - 1\n",
    "\n",
    "# Calculate the square root for image size\n",
    "import math\n",
    "image_size = math.ceil(math.sqrt(columns_minus_one))\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], random_seed=SEED)\n",
    "name = f\"IGTD_{image_size}x{image_size}\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], zoom=2, random_seed=SEED)\n",
    "name = f\"IGTD_{image_size*2}x{image_size*2}\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], zoom=4, random_seed=SEED)\n",
    "name = f\"IGTD_{image_size*4}x{image_size*4}\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], fea_dist_method='Euclidean', image_dist_method='Euclidean', random_seed=SEED)\n",
    "name = f\"IGTD_{image_size}x{image_size}_fEuclidean_iEuclidean\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 3: REFINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = REFINED(problem= problem_type, random_seed=SEED)\n",
    "name = f\"REFINED\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = REFINED(problem= problem_type, zoom=2, random_seed=SEED)\n",
    "name = f\"REFINED_zoom2\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = REFINED(problem= problem_type, zoom=4, random_seed=SEED)\n",
    "name = f\"REFINED_zoom4\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 4: BAR GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = BarGraph(problem= problem_type)\n",
    "name = f\"BarGraph\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = BarGraph(problem= problem_type, zoom=2)\n",
    "name = f\"BarGraph_zoom2\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = BarGraph(problem= problem_type, zoom=4)\n",
    "name = f\"BarGraph_zoom4\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 5: DISTANCE MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = DistanceMatrix(problem= problem_type)\n",
    "name = f\"DistanceMatrix\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = DistanceMatrix(problem= problem_type, zoom=2)\n",
    "name = f\"DistanceMatrix_zoom2\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = DistanceMatrix(problem= problem_type, zoom=4)\n",
    "name = f\"DistanceMatrix_zoom4\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 6: COMBINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = Combination(problem= problem_type)\n",
    "name = f\"Combination\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = Combination(problem= problem_type, zoom=2)\n",
    "name = f\"Combination_zoom2\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = Combination(problem= problem_type, zoom=4)\n",
    "name = f\"Combination_zoom4\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 7: SUPERTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = SuperTML(problem= problem_type, random_seed=SEED)\n",
    "name = f\"SuperTML-EF\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = SuperTML(problem= problem_type, feature_importance=True, font_size=30, random_seed=SEED)\n",
    "name = f\"SuperTML-VF_FS30\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, attributes)\n",
    "model2 = try_create_model(create_model2, imgs_shape, attributes)\n",
    "model3 = None\n",
    "\n",
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model2\")\n",
    "model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, f\"{name}_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "if model3_metrics:\n",
    "    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL METRICS AND BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(base_path):\n",
    "    best_accuracy = float('-inf')\n",
    "    best_folder = None\n",
    "\n",
    "    # Walk through all directories and files in the base path\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file == f'{dataset_name}_metrics.txt':\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Read metrics from the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    metrics = f.read()\n",
    "                \n",
    "                # Parse the metrics into a dictionary\n",
    "                metrics_dict = {}\n",
    "                for line in metrics.splitlines():\n",
    "                    key, value = line.split(': ')\n",
    "                    metrics_dict[key.strip()] = float(value.strip())\n",
    "                \n",
    "                # Check if the current folder has a better accuracy\n",
    "                if metrics_dict['test_accuracy'] > best_accuracy:\n",
    "                    best_accuracy = metrics_dict['test_accuracy']\n",
    "                    best_folder = root\n",
    "    \n",
    "    return best_folder, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_folder(old_folder_path):\n",
    "    # Extract the base name of the old folder\n",
    "    folder_name = os.path.basename(old_folder_path)\n",
    "    \n",
    "    # Create the new folder name by prepending \"best_\"\n",
    "    new_folder_name = f\"BEST_{folder_name}\"\n",
    "    \n",
    "    # Get the parent directory of the old folder\n",
    "    parent_dir = os.path.dirname(old_folder_path)\n",
    "    \n",
    "    # Create the full path for the new folder\n",
    "    new_folder_path = os.path.join(parent_dir, new_folder_name)\n",
    "    \n",
    "    # Rename the folder\n",
    "    os.rename(old_folder_path, new_folder_path)\n",
    "    \n",
    "    return new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "base_path = f\"logs/{dataset_name}/ViT+MLP_Binary\"\n",
    "best_folder, best_accuracy = find_best_model(base_path)\n",
    "best_folder = rename_folder(best_folder)\n",
    "print(f\"Best model folder: {best_folder}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tinto-HNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
