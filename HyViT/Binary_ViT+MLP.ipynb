{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiayu\\AppData\\Local\\Temp\\ipykernel_35248\\3945466512.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "#import openslide\n",
    "#from openslide.deepzoom import DeepZoomGenerator\n",
    "import tifffile as tifi\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,mean_absolute_percentage_error\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import vgg16, vgg19, resnet50, mobilenet, inception_resnet_v2, densenet, inception_v3, xception, nasnet, ResNet152V2\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, InputLayer, LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, Adamax\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from tensorflow.keras.layers import Input, Activation,MaxPooling2D, Concatenate, AveragePooling2D, Lambda\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Models of TINTOlib\n",
    "from TINTOlib.tinto import TINTO\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.combination import Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 64\n",
    "\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable to store dataset name\n",
    "dataset_name = 'preprocessed_heloc'\n",
    "results_path = f'logs/{dataset_name}/ViT+MLP_Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../Datasets_benchmark/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD AND PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ExternalRiskEstimate', 'MSinceOldestTradeOpen',\n",
       "       'MSinceMostRecentTradeOpen', 'AverageMInFile', 'NumSatisfactoryTrades',\n",
       "       'NumTrades60Ever2DerogPubRec', 'NumTrades90Ever2DerogPubRec',\n",
       "       'PercentTradesNeverDelq', 'MSinceMostRecentDelq',\n",
       "       'MaxDelq2PublicRecLast12M', 'MaxDelqEver', 'NumTotalTrades',\n",
       "       'NumTradesOpeninLast12M', 'PercentInstallTrades',\n",
       "       'MSinceMostRecentInqexcl7days', 'NumInqLast6M', 'NumInqLast6Mexcl7days',\n",
       "       'NetFractionRevolvingBurden', 'NetFractionInstallBurden',\n",
       "       'NumRevolvingTradesWBalance', 'NumInstallTradesWBalance',\n",
       "       'NumBank2NatlTradesWHighUtilization', 'PercentTradesWBalance',\n",
       "       'RiskPerformance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABEL ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9866    1\n",
      "9867    0\n",
      "9868    0\n",
      "9869    0\n",
      "9870    0\n",
      "Name: RiskPerformance, Length: 9871, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the last column with LabelEncoder\n",
    "df.iloc[:, -1] = label_encoder.fit_transform(df.iloc[:, -1])\n",
    "\n",
    "# Display the updated last column\n",
    "print(df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_and_preprocess_data(images_folder, image_model, problem_type):\n",
    "\n",
    "    # Generate the images if the folder does not exist\n",
    "    if not os.path.exists(images_folder):\n",
    "        #Generate thet images\n",
    "        image_model.generateImages(df, images_folder)\n",
    "    else:\n",
    "        print(\"The images are already generated\")\n",
    "\n",
    "    img_paths = os.path.join(images_folder,problem_type+\".csv\")\n",
    "\n",
    "    print(img_paths)\n",
    "    \n",
    "    imgs = pd.read_csv(img_paths)\n",
    "\n",
    "    # Update image paths\n",
    "    imgs[\"images\"] = images_folder + \"/\" + imgs[\"images\"]\n",
    "\n",
    "    # Combine datasets\n",
    "    combined_dataset = pd.concat([imgs, df], axis=1)\n",
    "\n",
    "    # Split data\n",
    "    df_x = combined_dataset.drop(df.columns[-1], axis=1).drop(\"class\", axis=1)\n",
    "    df_y = combined_dataset[\"class\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size=0.40, random_state=SEED)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.50, random_state=SEED)\n",
    "\n",
    "    # Numerical data\n",
    "    X_train_num = X_train.drop(\"images\", axis=1)\n",
    "    X_val_num = X_val.drop(\"images\", axis=1)\n",
    "    X_test_num = X_test.drop(\"images\", axis=1)\n",
    "\n",
    "    # Image data\n",
    "    X_train_img = np.array([cv2.imread(img) for img in X_train[\"images\"]])\n",
    "    X_val_img = np.array([cv2.imread(img) for img in X_val[\"images\"]])\n",
    "    X_test_img = np.array([cv2.imread(img) for img in X_test[\"images\"]])\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Scale numerical data\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "    X_val_num = pd.DataFrame(scaler.transform(X_val_num), columns=X_val_num.columns)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(X_test_num), columns=X_test_num.columns)\n",
    "\n",
    "    attributes = len(X_train_num.columns)\n",
    "    imgs_shape = X_train_img[0].shape\n",
    "\n",
    "    print(\"Images shape: \",imgs_shape)\n",
    "    print(\"Attributres: \",attributes)\n",
    "    pixels=X_train_img[0].shape[0]\n",
    "    print(\"Image size (pixels):\", pixels)\n",
    "\n",
    "    return X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL ARCHITECTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow.keras.layers as nn\n",
    "\n",
    "from tensorflow import einsum\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.tensorflow import Rearrange\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "class PreNorm(Layer):\n",
    "    def __init__(self, fn):\n",
    "        super(PreNorm, self).__init__()\n",
    "\n",
    "        self.norm = nn.LayerNormalization()\n",
    "        self.fn = fn\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return self.fn(self.norm(x), training=training)\n",
    "\n",
    "class MLP(Layer):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.0):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        def GELU():\n",
    "            def gelu(x, approximate=False):\n",
    "                if approximate:\n",
    "                    coeff = tf.cast(0.044715, x.dtype)\n",
    "                    return 0.5 * x * (1.0 + tf.tanh(0.7978845608028654 * (x + coeff * tf.pow(x, 3))))\n",
    "                else:\n",
    "                    return 0.5 * x * (1.0 + tf.math.erf(x / tf.cast(1.4142135623730951, x.dtype)))\n",
    "\n",
    "            return nn.Activation(gelu)\n",
    "\n",
    "        self.net = Sequential([\n",
    "            nn.Dense(units=hidden_dim),\n",
    "            GELU(),\n",
    "            nn.Dropout(rate=dropout),\n",
    "            nn.Dense(units=dim),\n",
    "            nn.Dropout(rate=dropout)\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return self.net(x, training=training)\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.0):\n",
    "        super(Attention, self).__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax()\n",
    "        self.to_qkv = nn.Dense(units=inner_dim * 3, use_bias=False)\n",
    "\n",
    "        if project_out:\n",
    "            self.to_out = [\n",
    "                nn.Dense(units=dim),\n",
    "                nn.Dropout(rate=dropout)\n",
    "            ]\n",
    "        else:\n",
    "            self.to_out = []\n",
    "\n",
    "        self.to_out = Sequential(self.to_out)\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        qkv = self.to_qkv(x)\n",
    "        qkv = tf.split(qkv, num_or_size_splits=3, axis=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n",
    "\n",
    "        # dots = tf.matmul(q, tf.transpose(k, perm=[0, 1, 3, 2])) * self.scale\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        # x = tf.matmul(attn, v)\n",
    "        x = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        x = rearrange(x, 'b h n d -> b n (h d)')\n",
    "        x = self.to_out(x, training=training)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Transformer(Layer):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.0):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        for _ in range(depth):\n",
    "            self.layers.append([\n",
    "                PreNorm(Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
    "                PreNorm(MLP(dim, mlp_dim, dropout=dropout))\n",
    "            ])\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        for attn, mlp in self.layers:\n",
    "            x = attn(x, training=training) + x\n",
    "            x = mlp(x, training=training) + x\n",
    "\n",
    "        return x\n",
    "\n",
    "class ViT(Model):\n",
    "    def __init__(self, image_size, patch_size, dim, depth, heads, mlp_dim,\n",
    "                 pool='cls', dim_head=64, dropout=0.0, emb_dropout=0.0):\n",
    "        \"\"\"\n",
    "            image_size: int.\n",
    "            -> Image size. If you have rectangular images, make sure your image size is the maximum of the width and height\n",
    "            patch_size: int.\n",
    "            -> Number of patches. image_size must be divisible by patch_size.\n",
    "            -> The number of patches is: n = (image_size // patch_size) ** 2 and n must be greater than 16.\n",
    "            num_classes: int.\n",
    "            -> Number of classes to classify.\n",
    "            dim: int.\n",
    "            -> Last dimension of output tensor after linear transformation nn.Linear(..., dim).\n",
    "            depth: int.\n",
    "            -> Number of Transformer blocks.\n",
    "            heads: int.\n",
    "            -> Number of heads in Multi-head Attention layer.\n",
    "            mlp_dim: int.\n",
    "            -> Dimension of the MLP (FeedForward) layer.\n",
    "            dropout: float between [0, 1], default 0..\n",
    "            -> Dropout rate.\n",
    "            emb_dropout: float between [0, 1], default 0.\n",
    "            -> Embedding dropout rate.\n",
    "            pool: string, either cls token pooling or mean pooling\n",
    "        \"\"\"\n",
    "        super(ViT, self).__init__()\n",
    "\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.patch_embedding = Sequential([\n",
    "            Rearrange('b (h p1) (w p2) c -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width),\n",
    "            nn.Dense(units=dim)\n",
    "        ], name='patch_embedding')\n",
    "\n",
    "        self.pos_embedding = tf.Variable(initial_value=tf.random.normal([1, num_patches + 1, dim]))\n",
    "        self.cls_token = tf.Variable(initial_value=tf.random.normal([1, 1, dim]))\n",
    "        self.dropout = nn.Dropout(rate=emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "\n",
    "    def call(self, img, training=True, **kwargs):\n",
    "        x = self.patch_embedding(img)\n",
    "        b, n, d = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n",
    "        x = tf.concat([cls_tokens, x], axis=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        x = self.transformer(x, training=training)\n",
    "\n",
    "        if self.pool == 'mean':\n",
    "            x = tf.reduce_mean(x, axis=1)\n",
    "        else:\n",
    "            x = x[:, 0]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT + MLP\n",
    "\n",
    "def create_model1(imgs_shape, attributes):\n",
    "    # ViT branch\n",
    "    vit_input = Input(shape=imgs_shape)\n",
    "\n",
    "    vit_model = ViT(\n",
    "        image_size = imgs_shape[0],\n",
    "        patch_size = imgs_shape[0],\n",
    "        dim = 64,\n",
    "        depth = 2,\n",
    "        heads = 4,\n",
    "        mlp_dim = 128,\n",
    "        dropout = 0.1,\n",
    "        emb_dropout = 0.1\n",
    "    )\n",
    "\n",
    "    # Wrap the ViT model call in a Lambda layer\n",
    "    vit_output = Lambda(lambda x: vit_model(x), output_shape=(64,))(vit_input)\n",
    "\n",
    "    vit_output = Dense(32, activation='relu')(vit_output)\n",
    "    vit_output = Dense(16, activation='relu')(vit_output)\n",
    "\n",
    "    # MLP branch\n",
    "    mlp_input = Input(shape=(attributes,))\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_input)\n",
    "    mlp_output = Dense(32, activation='relu')(mlp_output)\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_output)\n",
    "\n",
    "    # Concatenate the outputs of CNN and MLP branches\n",
    "    concat_output = Concatenate()([vit_output, mlp_output])\n",
    "\n",
    "    # Final MLP\n",
    "    final_output = Dense(32, activation='relu')(concat_output)\n",
    "    final_output = Dense(16, activation='relu')(final_output)\n",
    "    final_output = Dense(8, activation='relu')(final_output)\n",
    "    final_output = Dense(1)(final_output)  # Output layer for regression\n",
    "\n",
    "    # Create the hybrid model\n",
    "    model1 = Model(inputs=[mlp_input, vit_input], outputs=final_output)\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT with patch size as divisor of image size\n",
    "# ViT + MLP\n",
    "\n",
    "def find_divisors(n):\n",
    "    divisors = []\n",
    "    for i in range(1, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            divisors.append(i)\n",
    "            if i != n // i:  # Check to include both divisors if they are not the same\n",
    "                divisors.append(n // i)\n",
    "    divisors.sort()\n",
    "    return divisors\n",
    "\n",
    "def create_model2(imgs_shape, attributes):\n",
    "    divisors = find_divisors(imgs_shape[0])\n",
    "    \n",
    "    vit_input = Input(shape=imgs_shape)\n",
    "\n",
    "    vit_model = ViT(\n",
    "        image_size = imgs_shape[0],\n",
    "        patch_size = divisors[-2],\n",
    "        dim = 64,\n",
    "        depth = 2,\n",
    "        heads = 4,\n",
    "        mlp_dim = 128,\n",
    "        dropout = 0.1,\n",
    "        emb_dropout = 0.1\n",
    "    )\n",
    "\n",
    "    # Wrap the ViT model call in a Lambda layer\n",
    "    vit_output = Lambda(lambda x: vit_model(x), output_shape=(64,))(vit_input)\n",
    "\n",
    "    vit_output = Dense(64, activation='relu')(vit_output)\n",
    "    vit_output = Dense(32, activation='relu')(vit_output)\n",
    "    vit_output = Dense(16, activation='relu')(vit_output)\n",
    "\n",
    "    # MLP branch\n",
    "    mlp_input = Input(shape=(attributes,))\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_input)\n",
    "    mlp_output = Dense(32, activation='relu')(mlp_output)\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_output)\n",
    "\n",
    "    # Concatenate the outputs of CNN and MLP branches\n",
    "    concat_output = Concatenate()([vit_output, mlp_output])\n",
    "\n",
    "    # Final MLP\n",
    "    final_output = Dense(32, activation='relu')(concat_output)\n",
    "    final_output = Dense(16, activation='relu')(final_output)\n",
    "    final_output = Dense(8, activation='relu')(final_output)\n",
    "    final_output = Dense(1, activation='sigmoid')(final_output)  # Output layer for regression\n",
    "\n",
    "    # Create the hybrid model\n",
    "    model2 = Model(inputs=[mlp_input, vit_input], outputs=final_output)\n",
    "\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    #tf.keras.metrics.TruePositives(name = 'tp'),\n",
    "    #tf.keras.metrics.FalsePositives(name = 'fp'),\n",
    "    #tf.keras.metrics.TrueNegatives(name = 'tn'),\n",
    "    #tf.keras.metrics.FalseNegatives(name = 'fn'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name ='accuracy'),\n",
    "    tf.keras.metrics.Precision(name = 'precision'),\n",
    "    tf.keras.metrics.Recall(name = 'recall'),\n",
    "    tf.keras.metrics.AUC(name = 'auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPILE AND FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, model_name, batch_size=32, epochs=200, lr=1e-3):\n",
    "\n",
    "    opt = Adam(learning_rate=lr)\n",
    "\n",
    "    # Define the early stopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',  # Monitor the validation loss\n",
    "        min_delta=0.001,     # Minimum change in the monitored quantity to qualify as an improvement\n",
    "        patience=20,          # Number of epochs with no improvement after which training will be stopped\n",
    "        verbose=1,           # Print messages when the callback takes an action\n",
    "        mode='min',           # Training will stop when the quantity monitored has stopped decreasing\n",
    "        restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "    )\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=opt,\n",
    "        metrics=METRICS\n",
    "    )\n",
    "\n",
    "    model_history = model.fit(\n",
    "        x=[X_train_num,X_train_img], y=y_train,\n",
    "        validation_data=([X_val_num,X_val_img], y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    os.makedirs(f\"models/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['loss'], color = 'red', label = 'loss')\n",
    "    plt.plot(model_history.history['val_loss'], color = 'green', label = 'val loss')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/loss_plot.png\")\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['accuracy'], color = 'red', label = 'accuracy')\n",
    "    plt.plot(model_history.history['val_accuracy'], color = 'green', label = 'val accuracy')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/accuracy_plot.png\")\n",
    "\n",
    "    # Save the model\n",
    "    os.makedirs(f\"models/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "    model.save(f\"models/{dataset_name}/{model_name}/model_{dataset_name}.keras\")\n",
    "\n",
    "    # Evaluate the model on the training set\n",
    "    train_scores = model.evaluate([X_train_num,X_train_img], y_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_scores = model.evaluate([X_val_num,X_val_img], y_val)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    score_test = model.evaluate([X_test_num,X_test_img], y_test)\n",
    "\n",
    "    # Save training, validation, and test scores\n",
    "    metrics = {\n",
    "        'train_loss': train_scores[0],\n",
    "        'train_accuracy': train_scores[1],\n",
    "        'train_precision': train_scores[2],\n",
    "        'train_recall': train_scores[3],\n",
    "        'train_auc': train_scores[4],\n",
    "        'val_loss': val_scores[0],\n",
    "        'val_accuracy': val_scores[1],\n",
    "        'val_precision': val_scores[2],\n",
    "        'val_recall': val_scores[3],\n",
    "        'val_auc': val_scores[4],\n",
    "        'test_loss': score_test[0],\n",
    "        'test_accuracy': score_test[1],\n",
    "        'test_precision': score_test[2],\n",
    "        'test_recall': score_test[3],\n",
    "        'test_auc': score_test[4]\n",
    "    }\n",
    "\n",
    "    # Save metrics to a file\n",
    "    os.makedirs(f'{results_path}/{model_name}', exist_ok=True)\n",
    "    with open(f'{results_path}/{model_name}/{dataset_name}_metrics.txt', 'w') as f:\n",
    "        for key, value in metrics.items():\n",
    "            f.write(f'{key}: {value}\\n')\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test,dataset_name, model_name, batch_size=32, epochs=200, lr=1e-3):\n",
    "    try:\n",
    "        metrics = compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test,dataset_name, model_name, batch_size, epochs, lr)\n",
    "        return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to compile and fit {model_name}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"supervised\"\n",
    "#image_model = REFINED(problem= problem_type,hcIterations=5)\n",
    "image_model = TINTO(problem= problem_type, blur=True)\n",
    "#image_model = IGTD(problem= problem_type)\n",
    "#image_model = BarGraph(problem= problem_type)\n",
    "#image_model = DistanceMatrix(problem= problem_type)\n",
    "#image_model = Combination(problem= problem_type)\n",
    "#image_model = SuperTML(problem= problem_type)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Binary/{dataset_name}/images_{dataset_name}_IGTD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"supervised\"\n",
    "image_model = IGTD(problem= problem_type, scale=[3,3])\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Binary/{dataset_name}/images_{dataset_name}_IGTD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are already generated\n",
      "../HyNNImages/Binary/preprocessed_heloc/images_preprocessed_heloc_IGTD\\supervised.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape:  (5, 5, 3)\n",
      "Attributres:  23\n",
      "Image size (pixels): 5\n"
     ]
    }
   ],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = create_model1(imgs_shape, attributes)\n",
    "model2 = create_model2(imgs_shape, attributes)\n",
    "#model3 = create_model3(imgs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:From c:\\Users\\jiayu\\anaconda3\\envs\\Tinto-HNN\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Failed to compile and fit IGTD_model1: Exception encountered when calling ViT.call().\n",
      "\n",
      "\u001b[1munsupported operand type(s) for *=: 'int' and 'NoneType'\u001b[0m\n",
      "\n",
      "Arguments received by ViT.call():\n",
      "  • img=tf.Tensor(shape=(None, 5, 5, 3), dtype=float32)\n",
      "  • training=True\n",
      "  • kwargs=<class 'inspect._empty'>\n",
      "Epoch 1/200\n",
      "Failed to compile and fit IGTD_Model2: Exception encountered when calling ViT.call().\n",
      "\n",
      "\u001b[1munsupported operand type(s) for *=: 'int' and 'NoneType'\u001b[0m\n",
      "\n",
      "Arguments received by ViT.call():\n",
      "  • img=tf.Tensor(shape=(None, 5, 5, 3), dtype=float32)\n",
      "  • training=True\n",
      "  • kwargs=<class 'inspect._empty'>\n"
     ]
    }
   ],
   "source": [
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"IGTD_model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"IGTD_Model2\")\n",
    "#model3_metrics = safe_compile_and_fit(model3, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"TINTO_Model3\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)\n",
    "#if model3_metrics:\n",
    "#    print(\"Model 3 Metrics:\", model3_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(base_path):\n",
    "    best_accuracy = float('-inf')\n",
    "    best_folder = None\n",
    "\n",
    "    # Walk through all directories and files in the base path\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file == f'{dataset_name}_metrics.txt':\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Read metrics from the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    metrics = f.read()\n",
    "                \n",
    "                # Parse the metrics into a dictionary\n",
    "                metrics_dict = {}\n",
    "                for line in metrics.splitlines():\n",
    "                    key, value = line.split(': ')\n",
    "                    metrics_dict[key.strip()] = float(value.strip())\n",
    "                \n",
    "                # Check if the current folder has a better accuracy\n",
    "                if metrics_dict['test_accuracy'] > best_accuracy:\n",
    "                    best_accuracy = metrics_dict['test_accuracy']\n",
    "                    best_folder = root\n",
    "    \n",
    "    return best_folder, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_folder(old_folder_path):\n",
    "    # Extract the base name of the old folder\n",
    "    folder_name = os.path.basename(old_folder_path)\n",
    "    \n",
    "    # Create the new folder name by prepending \"best_\"\n",
    "    new_folder_name = f\"BEST_{folder_name}\"\n",
    "    \n",
    "    # Get the parent directory of the old folder\n",
    "    parent_dir = os.path.dirname(old_folder_path)\n",
    "    \n",
    "    # Create the full path for the new folder\n",
    "    new_folder_path = os.path.join(parent_dir, new_folder_name)\n",
    "    \n",
    "    # Rename the folder\n",
    "    os.rename(old_folder_path, new_folder_path)\n",
    "    \n",
    "    return new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/ViT+MLP_Binary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m best_folder, best_accuracy \u001b[38;5;241m=\u001b[39m find_best_model(base_path)\n\u001b[1;32m----> 4\u001b[0m best_folder \u001b[38;5;241m=\u001b[39m \u001b[43mrename_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model folder: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m, in \u001b[0;36mrename_folder\u001b[1;34m(old_folder_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrename_folder\u001b[39m(old_folder_path):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Extract the base name of the old folder\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     folder_name \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_folder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Create the new folder name by prepending \"best_\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     new_folder_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBEST_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m<frozen ntpath>:244\u001b[0m, in \u001b[0;36mbasename\u001b[1;34m(p)\u001b[0m\n",
      "File \u001b[1;32m<frozen ntpath>:213\u001b[0m, in \u001b[0;36msplit\u001b[1;34m(p)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "base_path = f\"logs/{dataset_name}/ViT+MLP_Binary\"\n",
    "best_folder, best_accuracy = find_best_model(base_path)\n",
    "best_folder = rename_folder(best_folder)\n",
    "print(f\"Best model folder: {best_folder}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tinto-HNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
