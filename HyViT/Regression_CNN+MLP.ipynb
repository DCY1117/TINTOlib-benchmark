{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "#import openslide\n",
    "#from openslide.deepzoom import DeepZoomGenerator\n",
    "import tifffile as tifi\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,mean_absolute_percentage_error\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import vgg16, vgg19, resnet50, mobilenet, inception_resnet_v2, densenet, inception_v3, xception, nasnet, ResNet152V2\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, InputLayer, LayerNormalization\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.optimizers import SGD, Adam, Adadelta, Adamax\n",
    "from keras import layers, models, Model\n",
    "from keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from keras.layers import Input, Activation,MaxPooling2D, Concatenate, AveragePooling2D\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Models of TINTOlib\n",
    "from TINTOlib.tinto import TINTO\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.combination import Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 64\n",
    "\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable to store dataset name\n",
    "dataset_name = 'boston'\n",
    "results_path = f'logs/{dataset_name}/CNN+MLP_Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../Datasets_benchmark/Regression/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD AND PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_and_preprocess_data(images_folder, image_model, problem_type):\n",
    "\n",
    "    # Generate the images if the folder does not exist\n",
    "    if not os.path.exists(images_folder):\n",
    "        #Generate thet images\n",
    "        image_model.generateImages(df, images_folder)\n",
    "    else:\n",
    "        print(\"The images are already generated\")\n",
    "\n",
    "    img_paths = os.path.join(images_folder,problem_type+\".csv\")\n",
    "\n",
    "    print(img_paths)\n",
    "    \n",
    "    imgs = pd.read_csv(img_paths)\n",
    "\n",
    "    # Update image paths\n",
    "    imgs[\"images\"] = images_folder + \"/\" + imgs[\"images\"]\n",
    "\n",
    "    # Combine datasets\n",
    "    combined_dataset = pd.concat([imgs, df], axis=1)\n",
    "\n",
    "    # Split data\n",
    "    df_x = combined_dataset.drop(df.columns[-1], axis=1).drop(\"values\", axis=1)\n",
    "    df_y = combined_dataset[\"values\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size=0.20, random_state=SEED)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.50, random_state=SEED)\n",
    "\n",
    "    # Numerical data\n",
    "    X_train_num = X_train.drop(\"images\", axis=1)\n",
    "    X_val_num = X_val.drop(\"images\", axis=1)\n",
    "    X_test_num = X_test.drop(\"images\", axis=1)\n",
    "\n",
    "    # Image data\n",
    "    X_train_img = np.array([cv2.imread(img) for img in X_train[\"images\"]])\n",
    "    X_val_img = np.array([cv2.imread(img) for img in X_val[\"images\"]])\n",
    "    X_test_img = np.array([cv2.imread(img) for img in X_test[\"images\"]])\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Scale numerical data\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "    X_val_num = pd.DataFrame(scaler.transform(X_val_num), columns=X_val_num.columns)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(X_test_num), columns=X_test_num.columns)\n",
    "\n",
    "    attributes = len(X_train_num.columns)\n",
    "    imgs_shape = X_train_img[0].shape\n",
    "\n",
    "    print(\"Images shape: \",imgs_shape)\n",
    "    print(\"Attributres: \",attributes)\n",
    "    pixels=X_train_img[0].shape[0]\n",
    "    print(\"Image size (pixels):\", pixels)\n",
    "\n",
    "    return X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL ARCHITECTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small CNN + MLP\n",
    "\n",
    "def create_model1(attributes, imgs_shape):\n",
    "\n",
    "    # MLP branch\n",
    "    mlp_input = Input(shape=imgs_shape)\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_input)\n",
    "    mlp_output = Dense(32, activation='relu')(mlp_output)\n",
    "    mlp_output = Dense(16, activation='relu')(mlp_output)\n",
    "\n",
    "    # CNN branch\n",
    "    cnn_input = Input(shape=(attributes,))\n",
    "    cnn_output = Conv2D(4, (2, 2), activation='relu')(cnn_input)\n",
    "    cnn_output = Flatten()(cnn_output)\n",
    "\n",
    "    # Concatenate the outputs of CNN and MLP branches\n",
    "    concat_output = Concatenate()([cnn_output, mlp_output])\n",
    "\n",
    "    # Final MLP layers\n",
    "    final_output = Dense(32, activation='relu')(concat_output)\n",
    "    final_output = Dense(16, activation='relu')(final_output)\n",
    "    final_output = Dense(8, activation='relu')(final_output)\n",
    "    final_output = Dense(1, activation='linear')(final_output)  # Output layer for regression\n",
    "\n",
    "    # Create and return the model\n",
    "    model1 = Model(inputs=[mlp_input, cnn_input], outputs=final_output)\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medium CNN + MLP\n",
    "\n",
    "def create_model2(attributes, imgs_shape):\n",
    "\n",
    "    # MLP branch\n",
    "    mlp_dropout = 0.1\n",
    "    mlp_input = Input(shape=(attributes,))\n",
    "    # MLP brach 1\n",
    "    mlp_1 = Dense(1024, activation='relu')(mlp_input)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    mlp_1 = Dense(512, activation='relu')(mlp_1)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    mlp_1 = Dense(256, activation='relu')(mlp_1)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    mlp_1 = Dense(128, activation='relu')(mlp_1)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    mlp_1 = Dense(64, activation='relu')(mlp_1)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    mlp_1 = Dense(32, activation='relu')(mlp_1)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    mlp_1 = Dense(16, activation='relu')(mlp_1)\n",
    "    mlp_1 = BatchNormalization()(mlp_1)\n",
    "    mlp_1 = Dropout(mlp_dropout)(mlp_1)\n",
    "\n",
    "    # MLP brach 2\n",
    "    mlp_2 = Dense(1024, activation='relu')(mlp_input)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_2 = Dense(512, activation='relu')(mlp_2)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_2 = Dense(256, activation='relu')(mlp_2)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_2 = Dense(128, activation='relu')(mlp_2)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_2 = Dense(64, activation='relu')(mlp_2)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_2 = Dense(32, activation='relu')(mlp_2)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_2 = Dense(16, activation='relu')(mlp_2)\n",
    "    mlp_2 = BatchNormalization()(mlp_2)\n",
    "    mlp_2 = Dropout(mlp_dropout)(mlp_2)\n",
    "\n",
    "    mlp_output = Concatenate(axis=1)([mlp_1, mlp_2])\n",
    "\n",
    "    # CNN branch\n",
    "    cnn_dropout = 0.1\n",
    "    cnn_input = Input(shape=imgs_shape)\n",
    "    # CNN branch 1\n",
    "    tower_1 = Conv2D(16, (3,3), activation='relu',padding=\"same\")(cnn_input)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(cnn_dropout)(tower_1)\n",
    "\n",
    "    tower_1 = Conv2D(32, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(cnn_dropout)(tower_1)\n",
    "\n",
    "    tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(cnn_dropout)(tower_1)\n",
    "\n",
    "    tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "    tower_1 = BatchNormalization()(tower_1)\n",
    "    tower_1 = Activation('relu')(tower_1)\n",
    "    tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "    tower_1 = Dropout(cnn_dropout)(tower_1)\n",
    "\n",
    "    # CNN branch 2\n",
    "    tower_2 = Conv2D(16, (5,5), activation='relu',padding=\"same\")(cnn_input)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(cnn_dropout)(tower_2)\n",
    "\n",
    "    tower_2 = Conv2D(32, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(cnn_dropout)(tower_2)\n",
    "\n",
    "    tower_2 = Conv2D(64, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(cnn_dropout)(tower_2)\n",
    "\n",
    "    tower_2 = Conv2D(64, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "    tower_2 = BatchNormalization()(tower_2)\n",
    "    tower_2 = Activation('relu')(tower_2)\n",
    "    tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "    tower_2 = Dropout(cnn_dropout)(tower_2)\n",
    "\n",
    "    #Concatenate CNN branches\n",
    "    merged_cnn = Concatenate(axis=1)([tower_1, tower_2])\n",
    "\n",
    "    #Flatten\n",
    "    merged = Flatten()(merged_cnn)\n",
    "\n",
    "    #Dense layers\n",
    "    out = Dense(256, activation='relu')(merged)\n",
    "    out = Dropout(cnn_dropout)(merged)\n",
    "    out = Dense(128, activation='sigmoid')(out)\n",
    "    out = Dropout(cnn_dropout)(out)\n",
    "    out = Dense(64, activation='sigmoid')(out)\n",
    "    out = Dropout(cnn_dropout)(out)\n",
    "    out = Dense(32, activation='sigmoid')(out)\n",
    "    cnn_output = Dropout(cnn_dropout)(out)\n",
    "\n",
    "    # Concatenate the outputs of CNN and MLP branches\n",
    "    concat_output = Concatenate()([mlp_output, cnn_output])\n",
    "\n",
    "    # Final MLP layers\n",
    "    final_output = Dense(48, activation='relu')(concat_output)\n",
    "    final_output = Dense(1, activation='linear')(final_output)  # Output layer for regression\n",
    "\n",
    "    # Create and return the model\n",
    "    model2 = Model(inputs=[mlp_input, cnn_input], outputs=final_output)\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    SS_res = K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    r2 = 1 - SS_res / (SS_tot + K.epsilon())\n",
    "    return r2\n",
    "\n",
    "METRICS = [\n",
    "    tf.keras.metrics.MeanSquaredError(name = 'mse'),\n",
    "    tf.keras.metrics.MeanAbsoluteError(name = 'mae'),\n",
    "    tf.keras.metrics.RootMeanSquaredError(name = 'rmse'),\n",
    "    r_square,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPILE AND FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, model_name, batch_size=32, epochs=200, lr=1e-3):\n",
    "\n",
    "    opt = Adam(learning_rate=lr)\n",
    "\n",
    "    # Define the early stopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',  # Monitor the validation loss\n",
    "        min_delta=0.001,     # Minimum change in the monitored quantity to qualify as an improvement\n",
    "        patience=20,          # Number of epochs with no improvement after which training will be stopped\n",
    "        verbose=1,           # Print messages when the callback takes an action\n",
    "        mode='min',           # Training will stop when the quantity monitored has stopped decreasing\n",
    "        restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "    )\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=opt,\n",
    "        metrics=METRICS\n",
    "    )\n",
    "\n",
    "    model_history = model.fit(\n",
    "        x=[X_train_num,X_train_img], y=y_train,\n",
    "        validation_data=([X_val_num,X_val_img], y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    os.makedirs(f\"models/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['loss'], color = 'red', label = 'loss')\n",
    "    plt.plot(model_history.history['val_loss'], color = 'green', label = 'val loss')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/loss_plot.png\")\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['mse'], color = 'red', label = 'mse')\n",
    "    plt.plot(model_history.history['val_mse'], color = 'green', label = 'val mse')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/mse_plot.png\")\n",
    "\n",
    "    plt.figure()  # Start a new figure\n",
    "    plt.plot(model_history.history['rmse'], color = 'red', label = 'rmse')\n",
    "    plt.plot(model_history.history['val_rmse'], color = 'green', label = 'val rmse')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig(f\"models/{dataset_name}/{model_name}/rmse_plot.png\")\n",
    "\n",
    "    # Save the model\n",
    "    os.makedirs(f\"models/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "    model.save(f\"models/{dataset_name}/{model_name}/model_{dataset_name}.keras\")\n",
    "\n",
    "    # Evaluate the model on the training set\n",
    "    train_scores = model.evaluate([X_train_num,X_train_img], y_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_scores = model.evaluate([X_val_num,X_val_img], y_val)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    score_test = model.evaluate([X_test_num,X_test_img], y_test)\n",
    "\n",
    "    # Save training, validation, and test scores\n",
    "    metrics = {\n",
    "        'train_loss': train_scores[0],\n",
    "        'train_mse': train_scores[1],\n",
    "        'train_mae': train_scores[2],\n",
    "        'train_rmse': train_scores[3],\n",
    "        'train_r2': train_scores[4],\n",
    "        'val_loss': val_scores[0],\n",
    "        'val_mse': val_scores[1],\n",
    "        'val_mae': val_scores[2],\n",
    "        'val_rmse': val_scores[3],\n",
    "        'val_r2': val_scores[4],\n",
    "        'test_loss': score_test[0],\n",
    "        'test_mse': score_test[1],\n",
    "        'test_mae': score_test[2],\n",
    "        'test_rmse': score_test[3],\n",
    "        'test_r2': score_test[4]\n",
    "    }\n",
    "\n",
    "    # Save metrics to a file\n",
    "    os.makedirs(f'{results_path}/{model_name}', exist_ok=True)\n",
    "    with open(f'{results_path}/{model_name}/{dataset_name}_metrics.txt', 'w') as f:\n",
    "        for key, value in metrics.items():\n",
    "            f.write(f'{key}: {value}\\n')\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test,dataset_name, model_name, batch_size=32, epochs=200, lr=1e-3):\n",
    "    try:\n",
    "        if model is None:\n",
    "            print(f\"Model {model_name} is None\")\n",
    "            return None\n",
    "        else:\n",
    "            metrics = compile_and_fit(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test,dataset_name, model_name, batch_size, epochs, lr)\n",
    "            return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to compile and fit {model_name}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_create_model(create_model_func, attributes, imgs_shape):\n",
    "    try:\n",
    "        model = create_model_func(attributes, imgs_shape)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.4807\n",
    "- Anadir capa final : 0.4225 Mejor\n",
    "- Anadir capa despues del CNN: 0.4408 No Mejor\n",
    "- Modelo mas complejo no mejora, podria ser porque este dataset tiene pocas features o puede ser que no tenga mucho spatial relationship y la CNN no sirva para nada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "#image_model = REFINED(problem= problem_type,hcIterations=5)\n",
    "image_model = TINTO(problem= problem_type, blur=True)\n",
    "#image_model = IGTD(problem= problem_type)\n",
    "#image_model = BarGraph(problem= problem_type)\n",
    "#image_model = DistanceMatrix(problem= problem_type)\n",
    "#image_model = Combination(problem= problem_type)\n",
    "#image_model = SuperTML(problem= problem_type)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_IGTD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, blur=True)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_TINTO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are already generated\n",
      "../HyNNImages/Regression/boston/images_boston_TINTO\\regression.csv\n",
      "Images shape:  (20, 20, 3)\n",
      "Attributres:  13\n",
      "Image size (pixels): 20\n"
     ]
    }
   ],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, attributes, imgs_shape)\n",
    "model2 = try_create_model(create_model2, attributes, imgs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"TINTO_model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"TINTO_model2\")\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = Combination(problem= problem_type, zoom=4)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_Combination_zoom4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are already generated\n",
      "../HyNNImages/Regression/boston/images_boston_Combination_zoom4\\regression.csv\n",
      "Images shape:  (52, 52, 3)\n",
      "Attributres:  13\n",
      "Image size (pixels): 52\n"
     ]
    }
   ],
   "source": [
    "X_train_num, X_val_num, X_test_num, X_train_img, X_val_img, X_test_img, y_train, y_val, y_test, imgs_shape, attributes = load_and_preprocess_data(images_folder, image_model, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = try_create_model(create_model1, imgs_shape, (attributes,))\n",
    "model2 = try_create_model(create_model2, imgs_shape, (attributes,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3383.7100 - mae: 36.5709 - mse: 2577.1797 - r_square: -58.0808 - rmse: 50.2006 - val_loss: 273.4509 - val_mae: 14.3304 - val_mse: 273.4509 - val_r_square: -4.4592 - val_rmse: 16.5364\n",
      "Epoch 2/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 244.3927 - mae: 12.7287 - mse: 244.3927 - r_square: -3.0865 - rmse: 15.4168 - val_loss: 71.7811 - val_mae: 6.6191 - val_mse: 71.7811 - val_r_square: -0.4071 - val_rmse: 8.4724\n",
      "Epoch 3/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 80.4563 - mae: 6.7544 - mse: 80.4563 - r_square: -0.2392 - rmse: 8.9678 - val_loss: 51.2891 - val_mae: 5.9385 - val_mse: 51.2891 - val_r_square: 0.0289 - val_rmse: 7.1616\n",
      "Epoch 4/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 53.7035 - mae: 5.3151 - mse: 53.7035 - r_square: 0.2610 - rmse: 7.3110 - val_loss: 53.4018 - val_mae: 5.8036 - val_mse: 53.4018 - val_r_square: -0.0296 - val_rmse: 7.3077\n",
      "Epoch 5/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 51.1992 - mae: 5.2082 - mse: 51.1992 - r_square: 0.2998 - rmse: 7.1380 - val_loss: 48.5654 - val_mae: 5.7354 - val_mse: 48.5654 - val_r_square: 0.0818 - val_rmse: 6.9689\n",
      "Epoch 6/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 47.7707 - mae: 4.9982 - mse: 47.7707 - r_square: 0.3462 - rmse: 6.8951 - val_loss: 45.2052 - val_mae: 5.3730 - val_mse: 45.2052 - val_r_square: 0.1660 - val_rmse: 6.7235\n",
      "Epoch 7/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.1168 - mae: 4.7837 - mse: 45.1168 - r_square: 0.3904 - rmse: 6.6988 - val_loss: 43.7626 - val_mae: 5.2468 - val_mse: 43.7626 - val_r_square: 0.1945 - val_rmse: 6.6153\n",
      "Epoch 8/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 43.1366 - mae: 4.6543 - mse: 43.1366 - r_square: 0.4194 - rmse: 6.5489 - val_loss: 43.4050 - val_mae: 5.1754 - val_mse: 43.4050 - val_r_square: 0.1964 - val_rmse: 6.5882\n",
      "Epoch 9/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 42.0651 - mae: 4.5990 - mse: 42.0651 - r_square: 0.4320 - rmse: 6.4673 - val_loss: 42.9865 - val_mae: 5.1478 - val_mse: 42.9865 - val_r_square: 0.2025 - val_rmse: 6.5564\n",
      "Epoch 10/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.3375 - mae: 4.5548 - mse: 41.3375 - r_square: 0.4417 - rmse: 6.4110 - val_loss: 42.6932 - val_mae: 5.1129 - val_mse: 42.6932 - val_r_square: 0.2036 - val_rmse: 6.5340\n",
      "Epoch 11/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.8261 - mae: 4.5280 - mse: 40.8261 - r_square: 0.4480 - rmse: 6.3714 - val_loss: 42.2010 - val_mae: 5.0674 - val_mse: 42.2010 - val_r_square: 0.2140 - val_rmse: 6.4962\n",
      "Epoch 12/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.3604 - mae: 4.5034 - mse: 40.3604 - r_square: 0.4536 - rmse: 6.3350 - val_loss: 42.1572 - val_mae: 5.0845 - val_mse: 42.1572 - val_r_square: 0.2108 - val_rmse: 6.4929\n",
      "Epoch 13/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.0678 - mae: 4.4917 - mse: 40.0678 - r_square: 0.4550 - rmse: 6.3128 - val_loss: 41.7859 - val_mae: 5.0626 - val_mse: 41.7859 - val_r_square: 0.2180 - val_rmse: 6.4642\n",
      "Epoch 14/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.7949 - mae: 4.4718 - mse: 39.7949 - r_square: 0.4582 - rmse: 6.2913 - val_loss: 41.3301 - val_mae: 5.0229 - val_mse: 41.3301 - val_r_square: 0.2293 - val_rmse: 6.4289\n",
      "Epoch 15/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.4866 - mae: 4.4517 - mse: 39.4866 - r_square: 0.4618 - rmse: 6.2671 - val_loss: 41.1579 - val_mae: 5.0188 - val_mse: 41.1579 - val_r_square: 0.2303 - val_rmse: 6.4154\n",
      "Epoch 16/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.4209 - mae: 4.4505 - mse: 39.4209 - r_square: 0.4602 - rmse: 6.2626 - val_loss: 40.5776 - val_mae: 4.9641 - val_mse: 40.5776 - val_r_square: 0.2483 - val_rmse: 6.3701\n",
      "Epoch 17/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.9686 - mae: 4.4126 - mse: 38.9686 - r_square: 0.4682 - rmse: 6.2257 - val_loss: 40.2246 - val_mae: 4.9304 - val_mse: 40.2246 - val_r_square: 0.2536 - val_rmse: 6.3423\n",
      "Epoch 18/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.9521 - mae: 4.4218 - mse: 38.9521 - r_square: 0.4651 - rmse: 6.2255 - val_loss: 40.0800 - val_mae: 4.9388 - val_mse: 40.0800 - val_r_square: 0.2567 - val_rmse: 6.3309\n",
      "Epoch 19/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.7011 - mae: 4.3989 - mse: 38.7011 - r_square: 0.4678 - rmse: 6.2054 - val_loss: 39.5203 - val_mae: 4.8619 - val_mse: 39.5203 - val_r_square: 0.2716 - val_rmse: 6.2865\n",
      "Epoch 20/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.6056 - mae: 4.3939 - mse: 38.6056 - r_square: 0.4676 - rmse: 6.1983 - val_loss: 39.2157 - val_mae: 4.8441 - val_mse: 39.2157 - val_r_square: 0.2760 - val_rmse: 6.2622\n",
      "Epoch 21/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.4634 - mae: 4.3913 - mse: 38.4634 - r_square: 0.4674 - rmse: 6.1875 - val_loss: 39.0621 - val_mae: 4.8620 - val_mse: 39.0621 - val_r_square: 0.2767 - val_rmse: 6.2500\n",
      "Epoch 22/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.3095 - mae: 4.3814 - mse: 38.3095 - r_square: 0.4670 - rmse: 6.1756 - val_loss: 38.6377 - val_mae: 4.8228 - val_mse: 38.6377 - val_r_square: 0.2874 - val_rmse: 6.2159\n",
      "Epoch 23/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.3095 - mae: 4.3824 - mse: 38.3095 - r_square: 0.4641 - rmse: 6.1764 - val_loss: 38.1492 - val_mae: 4.7871 - val_mse: 38.1492 - val_r_square: 0.2976 - val_rmse: 6.1765\n",
      "Epoch 24/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.2065 - mae: 4.3792 - mse: 38.2065 - r_square: 0.4632 - rmse: 6.1687 - val_loss: 37.8206 - val_mae: 4.7671 - val_mse: 37.8206 - val_r_square: 0.3036 - val_rmse: 6.1498\n",
      "Epoch 25/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.0142 - mae: 4.3668 - mse: 38.0142 - r_square: 0.4638 - rmse: 6.1536 - val_loss: 37.5353 - val_mae: 4.7879 - val_mse: 37.5353 - val_r_square: 0.3075 - val_rmse: 6.1266\n",
      "Epoch 26/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.9197 - mae: 4.3789 - mse: 37.9197 - r_square: 0.4612 - rmse: 6.1468 - val_loss: 37.1326 - val_mae: 4.7620 - val_mse: 37.1326 - val_r_square: 0.3135 - val_rmse: 6.0936\n",
      "Epoch 27/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.8184 - mae: 4.3740 - mse: 37.8184 - r_square: 0.4590 - rmse: 6.1395 - val_loss: 36.7683 - val_mae: 4.7922 - val_mse: 36.7683 - val_r_square: 0.3187 - val_rmse: 6.0637\n",
      "Epoch 28/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.5502 - mae: 4.3859 - mse: 37.5502 - r_square: 0.4597 - rmse: 6.1183 - val_loss: 36.4682 - val_mae: 4.7856 - val_mse: 36.4682 - val_r_square: 0.3209 - val_rmse: 6.0389\n",
      "Epoch 29/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.4293 - mae: 4.3845 - mse: 37.4293 - r_square: 0.4564 - rmse: 6.1096 - val_loss: 35.9969 - val_mae: 4.8073 - val_mse: 35.9969 - val_r_square: 0.3283 - val_rmse: 5.9997\n",
      "Epoch 30/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.9317 - mae: 4.3915 - mse: 36.9317 - r_square: 0.4611 - rmse: 6.0692 - val_loss: 35.6405 - val_mae: 4.8190 - val_mse: 35.6405 - val_r_square: 0.3310 - val_rmse: 5.9700\n",
      "Epoch 31/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.4690 - mae: 4.3853 - mse: 36.4690 - r_square: 0.4640 - rmse: 6.0318 - val_loss: 35.0749 - val_mae: 4.7979 - val_mse: 35.0749 - val_r_square: 0.3392 - val_rmse: 5.9224\n",
      "Epoch 32/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 35.7100 - mae: 4.3425 - mse: 35.7100 - r_square: 0.4728 - rmse: 5.9692 - val_loss: 34.6214 - val_mae: 4.8052 - val_mse: 34.6214 - val_r_square: 0.3445 - val_rmse: 5.8840\n",
      "Epoch 33/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.6066 - mae: 4.2844 - mse: 34.6066 - r_square: 0.4889 - rmse: 5.8763 - val_loss: 34.3391 - val_mae: 4.8420 - val_mse: 34.3391 - val_r_square: 0.3456 - val_rmse: 5.8600\n",
      "Epoch 34/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.4096 - mae: 4.2305 - mse: 33.4096 - r_square: 0.5060 - rmse: 5.7738 - val_loss: 33.7015 - val_mae: 4.8206 - val_mse: 33.7015 - val_r_square: 0.3538 - val_rmse: 5.8053\n",
      "Epoch 35/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.9270 - mae: 4.1208 - mse: 31.9270 - r_square: 0.5289 - rmse: 5.6440 - val_loss: 32.8972 - val_mae: 4.7824 - val_mse: 32.8972 - val_r_square: 0.3678 - val_rmse: 5.7356\n",
      "Epoch 36/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.1395 - mae: 4.0031 - mse: 30.1395 - r_square: 0.5580 - rmse: 5.4830 - val_loss: 31.9809 - val_mae: 4.7266 - val_mse: 31.9809 - val_r_square: 0.3850 - val_rmse: 5.6552\n",
      "Epoch 37/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1283 - mae: 3.8573 - mse: 28.1283 - r_square: 0.5912 - rmse: 5.2957 - val_loss: 30.3741 - val_mae: 4.5890 - val_mse: 30.3741 - val_r_square: 0.4213 - val_rmse: 5.5113\n",
      "Epoch 38/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25.7949 - mae: 3.6607 - mse: 25.7949 - r_square: 0.6306 - rmse: 5.0695 - val_loss: 28.0072 - val_mae: 4.3391 - val_mse: 28.0072 - val_r_square: 0.4776 - val_rmse: 5.2922\n",
      "Epoch 39/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.4109 - mae: 3.4280 - mse: 23.4109 - r_square: 0.6703 - rmse: 4.8274 - val_loss: 25.2613 - val_mae: 3.9763 - val_mse: 25.2613 - val_r_square: 0.5447 - val_rmse: 5.0261\n",
      "Epoch 40/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.2376 - mae: 3.2166 - mse: 21.2376 - r_square: 0.7062 - rmse: 4.5955 - val_loss: 23.0081 - val_mae: 3.5704 - val_mse: 23.0081 - val_r_square: 0.5999 - val_rmse: 4.7967\n",
      "Epoch 41/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.5838 - mae: 3.0367 - mse: 19.5838 - r_square: 0.7334 - rmse: 4.4107 - val_loss: 21.9441 - val_mae: 3.2224 - val_mse: 21.9441 - val_r_square: 0.6252 - val_rmse: 4.6845\n",
      "Epoch 42/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.5112 - mae: 2.9601 - mse: 18.5112 - r_square: 0.7516 - rmse: 4.2863 - val_loss: 21.8033 - val_mae: 3.0526 - val_mse: 21.8033 - val_r_square: 0.6234 - val_rmse: 4.6694\n",
      "Epoch 43/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.7301 - mae: 2.9266 - mse: 17.7301 - r_square: 0.7639 - rmse: 4.1936 - val_loss: 21.8172 - val_mae: 3.0480 - val_mse: 21.8172 - val_r_square: 0.6134 - val_rmse: 4.6709\n",
      "Epoch 44/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.0546 - mae: 2.8959 - mse: 17.0546 - r_square: 0.7740 - rmse: 4.1118 - val_loss: 22.2709 - val_mae: 3.1265 - val_mse: 22.2709 - val_r_square: 0.5925 - val_rmse: 4.7192\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage with two models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model1_metrics \u001b[38;5;241m=\u001b[39m \u001b[43msafe_compile_and_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCombination_zoom4_model1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m model2_metrics \u001b[38;5;241m=\u001b[39m safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombination_zoom4_model2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Print comparison of metrics only for models that ran successfully\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[35], line 7\u001b[0m, in \u001b[0;36msafe_compile_and_fit\u001b[1;34m(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, model_name, batch_size, epochs, lr)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_and_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[34], line 24\u001b[0m, in \u001b[0;36mcompile_and_fit\u001b[1;34m(model, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, model_name, batch_size, epochs, lr)\u001b[0m\n\u001b[0;32m      8\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[0;32m      9\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Monitor the validation loss\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,     \u001b[38;5;66;03m# Minimum change in the monitored quantity to qualify as an improvement\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Restore model weights from the epoch with the best value of the monitored quantity\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     19\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mopt,\n\u001b[0;32m     21\u001b[0m     metrics\u001b[38;5;241m=\u001b[39mMETRICS\n\u001b[0;32m     22\u001b[0m )\n\u001b[1;32m---> 24\u001b[0m model_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX_train_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train_img\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_val_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_val_img\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     34\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()  \u001b[38;5;66;03m# Start a new figure\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jiayu\\anaconda3\\envs\\Tinto-HNN\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jiayu\\anaconda3\\envs\\Tinto-HNN\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:312\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    310\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m--> 312\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menumerate_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jiayu\\anaconda3\\envs\\Tinto-HNN\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:645\u001b[0m, in \u001b[0;36mTFEpochIterator.enumerate_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 645\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distributed_dataset)\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches:\n\u001b[0;32m    647\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[0;32m    648\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution\n\u001b[0;32m    649\u001b[0m         ):\n",
      "File \u001b[1;32mc:\\Users\\jiayu\\anaconda3\\envs\\Tinto-HNN\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jiayu\\anaconda3\\envs\\Tinto-HNN\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:705\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    701\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 705\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jiayu\\anaconda3\\envs\\Tinto-HNN\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:744\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    741\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    742\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    743\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 744\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jiayu\\anaconda3\\envs\\Tinto-HNN\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3479\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage with two models\n",
    "model1_metrics = safe_compile_and_fit(model1, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"Combination_zoom4_model1\")\n",
    "model2_metrics = safe_compile_and_fit(model2, X_train_num, X_train_img, y_train, X_val_num, X_val_img, y_val, X_test_num, X_test_img, y_test, dataset_name, \"Combination_zoom4_model2\")\n",
    "\n",
    "\n",
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(base_path):\n",
    "    best_rmse = float('inf')\n",
    "    best_folder = None\n",
    "\n",
    "    # Walk through all directories and files in the base path\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file == f'{dataset_name}_metrics.txt':\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Read metrics from the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    metrics = f.read()\n",
    "                \n",
    "                # Parse the metrics into a dictionary\n",
    "                metrics_dict = {}\n",
    "                for line in metrics.splitlines():\n",
    "                    key, value = line.split(': ')\n",
    "                    metrics_dict[key.strip()] = float(value.strip())\n",
    "                \n",
    "                # Check if the current folder has a better validation loss\n",
    "                if metrics_dict['test_rmse'] < best_rmse:\n",
    "                    best_rmse = metrics_dict['test_rmse']\n",
    "                    best_folder = root\n",
    "    \n",
    "    return best_folder, best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_folder(old_folder_path):\n",
    "    # Extract the base name of the old folder\n",
    "    folder_name = os.path.basename(old_folder_path)\n",
    "    \n",
    "    # Create the new folder name by prepending \"best_\"\n",
    "    new_folder_name = f\"BEST_{folder_name}\"\n",
    "    \n",
    "    # Get the parent directory of the old folder\n",
    "    parent_dir = os.path.dirname(old_folder_path)\n",
    "    \n",
    "    # Create the full path for the new folder\n",
    "    new_folder_path = os.path.join(parent_dir, new_folder_name)\n",
    "    \n",
    "    # Rename the folder\n",
    "    os.rename(old_folder_path, new_folder_path)\n",
    "    \n",
    "    return new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model folder: logs/boston/CNN+MLP_Regression\\BEST_best_TINTO_model1\n",
      "Best RMSE: 2.8698511123657227\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "base_path = f\"logs/{dataset_name}/CNN+MLP_Regression\"\n",
    "best_folder, best_rmse = find_best_model(base_path)\n",
    "best_folder = rename_folder(best_folder)\n",
    "print(f\"Best model folder: {best_folder}\")\n",
    "print(f\"Best RMSE: {best_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tinto-HNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
